{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "213c36a2",
   "metadata": {},
   "source": [
    "# Aqui, insira um título"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce0616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import xgboost\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from skopt import forest_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from base import * \n",
    "from experimental import * \n",
    "import json\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da938cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bbb90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da5e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_path = '../data/'\n",
    "metadata = pd.read_csv(inp_path + 'metadata.csv')\n",
    "test = pd.read_csv(inp_path + 'test.csv').set_index('id')\n",
    "train = pd.read_csv(inp_path + 'train.csv').set_index('id')\n",
    "#train = train.sample(frac=1, random_state=0).reset_index(drop=True)  # shuffling dataset\n",
    "sub = pd.read_csv(inp_path + 'submission_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b1be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2484677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_instance(parameters):\n",
    "\n",
    "    # Parametros de classificação\n",
    "    classifier_parameters = dict(\n",
    "        map(\n",
    "            lambda x: (x[\"parameter\"], x[\"estimate\"]),\n",
    "            filter(lambda x: x[\"description\"] == \"classifier\", parameters),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Parâmetros de preprocessmento\n",
    "    params = pd.DataFrame(parameters).set_index(\"parameter\").to_dict(orient=\"index\")\n",
    "    \n",
    "    min_correlation = params[\"min_correlation\"][\"estimate\"]\n",
    "    z_score = params[\"z_score\"][\"estimate\"]\n",
    "    z_score_range = (-z_score, z_score)\n",
    "    polynomial_degree = 1\n",
    "    \n",
    "    estimator = RandomForestClassifier(n_jobs=n_jobs, random_state=42)\n",
    "\n",
    "    model = Model(\n",
    "        estimator,\n",
    "        classifier_params=classifier_parameters,\n",
    "        min_correlation=min_correlation,\n",
    "        z_score_range=z_score_range,\n",
    "        polynomial_degree=polynomial_degree,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e59b55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(X, y, parameters):\n",
    "\n",
    "#     # Parametros de classificação\n",
    "#     classifier_parameters = dict(\n",
    "#         map(\n",
    "#             lambda x: (x[\"parameter\"], x[\"estimate\"]),\n",
    "#             filter(lambda x: x[\"description\"] == \"classifier\", parameters),\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     # Parâmetros de preprocessmento\n",
    "#     params = pd.DataFrame(parameters).set_index(\"parameter\").to_dict(orient=\"index\")\n",
    "    \n",
    "#     min_correlation = params[\"min_correlation\"][\"estimate\"]\n",
    "#     z_score = params[\"z_score\"][\"estimate\"]\n",
    "#     z_score_range = (-z_score, z_score)\n",
    "#     polynomial_degree = 1\n",
    "    \n",
    "#     estimator = XGBClassifier(n_jobs=n_jobs, random_state=42, eval_metric=\"logloss\")\n",
    "\n",
    "#     model = Model(\n",
    "#         estimator,\n",
    "#         classifier_params=classifier_parameters,\n",
    "#         min_correlation=min_correlation,\n",
    "#         z_score_range=z_score_range,\n",
    "#         polynomial_degree=polynomial_degree,\n",
    "#     )\n",
    "    model = model_instance(parameters)\n",
    "    cv_score = -model.cross_validate_score(X, y)\n",
    "\n",
    "    return  cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c34233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run experimental.py\n",
    "\n",
    "\n",
    "    \n",
    "# new_parameters(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2038f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\t>>> param: [83, 'entropy', 13, 6, 4, 0.0, 0.9886724585380823, 3.813401418088005, 0.04565309006023782]\n",
      "\t>>> score: 0.6540584\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "1\t>>> param: [74, 'entropy', 13, 6, 3, 0.0, 0.9569212455318752, 3.740119646776995, 0.04523237277700162]\n",
      "\t>>> score: 0.64818\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "2\t>>> param: [70, 'entropy', 13, 6, 4, 0.040265405348648406, 0.9355339856207294, 3.6312224706596696, 0.04745098313757863]\n",
      "\t>>> score: 0.6163152\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "3\t>>> param: [65, 'entropy', 14, 5, 4, 0.0018683257126553207, 0.9583923305891245, 3.559636734714841, 0.044947176296360754]\n",
      "\t>>> score: 0.6469505\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "4\t>>> param: [67, 'entropy', 13, 6, 4, 0.049869006318700206, 0.9642045746115067, 3.6605773875641066, 0.04231518288737691]\n",
      "\t>>> score: 0.6138929\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "5\t>>> param: [66, 'entropy', 11, 5, 4, 0.031178103239431168, 0.9496820479482367, 3.715252681297327, 0.04106896489524929]\n",
      "\t>>> score: 0.6355605\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "6\t>>> param: [75, 'entropy', 10, 4, 4, 0.06313073704919547, 0.9182509093378923, 3.7041400553961266, 0.044303569300462774]\n",
      "\t>>> score: 0.5885075\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "7\t>>> param: [72, 'entropy', 11, 5, 4, 0.06815701612785517, 0.8713938493795941, 3.868383893381126, 0.04390131786187008]\n",
      "\t>>> score: 0.615323\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "8\t>>> param: [70, 'entropy', 13, 4, 4, 0.07728941555132066, 0.8555932566328769, 3.9924919314529457, 0.0461311585068044]\n",
      "\t>>> score: 0.6188528\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "9\t>>> param: [71, 'entropy', 14, 5, 4, 0.04735099293115447, 0.8440511452459036, 4.185535350131116, 0.0415253679401236]\n",
      "\t>>> score: 0.6138929\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "10\t>>> param: [68, 'entropy', 16, 5, 4, 0.02530349830948627, 0.7971435954327268, 3.9889991132087586, 0.042502817765341074]\n",
      "\t>>> score: 0.6379692\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "11\t>>> param: [71, 'entropy', 16, 5, 4, 0.04976988148269574, 0.7672472230627336, 4.178589004226468, 0.041584950489535984]\n",
      "\t>>> score: 0.6139183\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "12\t>>> param: [68, 'entropy', 16, 6, 4, 0.0003591069076372688, 0.8091132300851269, 4.120940636192002, 0.046489174796246265]\n",
      "\t>>> score: 0.6454802\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "13\t>>> param: [68, 'entropy', 17, 6, 4, 0.00882052858210796, 0.8176155325145392, 4.120676738219595, 0.047630757577848695]\n",
      "\t>>> score: 0.6400739\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "14\t>>> param: [73, 'entropy', 19, 6, 4, 0.0, 0.7700583365037916, 4.252251803857602, 0.04814292540759565]\n",
      "\t>>> score: 0.6435843\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "15\t>>> param: [65, 'entropy', 20, 6, 4, 0.0, 0.7731893789926984, 4.2281056686066405, 0.04417103586346422]\n",
      "\t>>> score: 0.6426731\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "16\t>>> param: [72, 'entropy', 20, 6, 4, 0.010851898076339885, 0.7965022310838478, 4.196518473157419, 0.042373599401885974]\n",
      "\t>>> score: 0.6399514\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "17\t>>> param: [70, 'entropy', 19, 6, 4, 0.0, 0.8174203825974492, 4.121724307444677, 0.04407707164656581]\n",
      "\t>>> score: 0.6415276\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "18\t>>> param: [70, 'entropy', 17, 6, 4, 0.017298124966970446, 0.7927325042922029, 4.214947158836039, 0.04279483523376295]\n",
      "\t>>> score: 0.6369722\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "19\t>>> param: [74, 'entropy', 15, 6, 4, 0.008256295575139967, 0.8269215033651682, 4.348264159747415, 0.04411873036316025]\n",
      "\t>>> score: 0.6422235\n",
      "\t>>> score-max: 0.6540584\n",
      "\n",
      "20\t>>> param: [71, 'entropy', 16, 5, 4, 0.0, 0.8680958977495794, 4.445654488048575, 0.04520478167979302]\n",
      "\t>>> score: 0.6479756\n",
      "\t>>> score-max: 0.6540584\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_iter = 100\n",
    "n_repetitions = 1\n",
    "\n",
    "\n",
    "for i in range(n_repetitions):\n",
    "\n",
    "    # Importando Parâmetros\n",
    "    with open(r\"parameters_opt.json\", \"r\") as read_file:\n",
    "        parameters = json.load(read_file)\n",
    "\n",
    "    X = train.drop(\"y\", 1)\n",
    "    y = train[\"y\"]\n",
    "\n",
    "    x = parameters\n",
    "    p = score_function(X, y, x)\n",
    "\n",
    "    xmax = x\n",
    "    pmax = p\n",
    "\n",
    "    for i in range(n_iter):\n",
    "\n",
    "        print( f\"\\n{i}\\t>>> param:\",[elem[\"estimate\"] for elem in x])\n",
    "        print(\"\\t>>> score:\", np.round(p, 7))\n",
    "        print(\"\\t>>> score-max:\", np.round(pmax, 7))\n",
    "\n",
    "        x0 = new_parameters(x)\n",
    "        p0 = score_function(X, y, x0)\n",
    "\n",
    "        A = min(1, p0 / p)\n",
    "        u = np.random.random()\n",
    "\n",
    "        if u <= A:\n",
    "            x = x0\n",
    "            p = p0\n",
    "\n",
    "        if p > pmax:\n",
    "            xmax = x0\n",
    "            pmax = p0\n",
    "\n",
    "    print( f\"\\n{i}\\t>>> param:\",[elem[\"estimate\"] for elem in xmax])\n",
    "    print(\"\\t>>> score:\", np.round(pmax, 7))\n",
    "    print(\"###################################################################\")\n",
    "    with open(\"parameters_opt.json\", \"w\") as file:\n",
    "        json.dump(xmax, file, indent=2, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fef333c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbor_x(parameters, epsilon):\n",
    "\n",
    "    new_parameters = deepcopy(parameters)\n",
    "\n",
    "    for elem in new_parameters:\n",
    "        if elem[\"type\"] == \"real\":\n",
    "            elem[\"estimate\"] = elem[\"estimate\"] + epsilon * np.diff(elem[\"range\"])[0]\n",
    "\n",
    "        elif elem[\"type\"] == \"integer\":\n",
    "            elem[\"estimate\"] = elem[\"estimate\"] + 1\n",
    "\n",
    "    return new_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6577e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_neighbor = neighbor_x(parameters, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ddb55c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6540584395785568"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4a957c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vector = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0062ef66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_estimators',\n",
       " 'criterion',\n",
       " 'max_depth',\n",
       " 'min_samples_split',\n",
       " 'min_samples_leaf',\n",
       " 'min_weight_fraction_leaf',\n",
       " 'max_features',\n",
       " 'z_score',\n",
       " 'min_correlation']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[elem['parameter'] for elem in parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705116c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6540584395785568\n",
      "0.6488070740566074\n",
      "0.6518552772353532\n",
      "0.6545192017672896\n",
      "0.6481275978083096\n",
      "0.6545192017672896\n",
      "0.6481275978083096\n",
      "0.6545192017672896\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "par = \"min_samples_leaf\"\n",
    "epsilon = 0.01\n",
    "alpha = 0.05\n",
    "grad_vector = {}\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    print(score_function(X, y, parameters))\n",
    "\n",
    "    final_parameters = deepcopy(parameters)\n",
    "\n",
    "    for par in [elem[\"parameter\"] for elem in parameters]:\n",
    "\n",
    "        par_dict = list(filter(lambda x: x[\"parameter\"] == par, parameters))[0]\n",
    "\n",
    "        ind = np.argwhere(np.array([elem[\"parameter\"] for elem in parameters]) == par)[0][0]\n",
    "\n",
    "        new_parameters = deepcopy(parameters)\n",
    "\n",
    "        if new_parameters[ind][\"type\"] == \"integer\":\n",
    "\n",
    "            delta = 1\n",
    "\n",
    "            new_parameters[ind][\"estimate\"] = new_parameters[0][\"estimate\"] + delta\n",
    "\n",
    "            s1 = score_function(X, y, parameters)\n",
    "\n",
    "            s2 = score_function(X, y, new_parameters)\n",
    "\n",
    "            grad = int((s2 - s1) / np.abs(s2 - s1))\n",
    "\n",
    "            final_parameters[ind][\"estimate\"] = np.clip(\n",
    "                final_parameters[ind][\"estimate\"] + grad, *final_parameters[ind][\"range\"]\n",
    "            )\n",
    "\n",
    "        elif new_parameters[ind][\"type\"] == \"real\":\n",
    "\n",
    "            try:\n",
    "                delta = epsilon * np.diff(new_parameters[ind][\"range\"])[0]\n",
    "\n",
    "                new_parameters[ind][\"estimate\"] = new_parameters[ind][\"estimate\"] + delta\n",
    "\n",
    "                s1 = score_function(X, y, parameters)\n",
    "\n",
    "                s2 = score_function(X, y, new_parameters)\n",
    "\n",
    "                grad = alpha * np.diff(new_parameters[ind][\"range\"])[0] * (s2 - s1) / delta\n",
    "            except:\n",
    "                grad = 0\n",
    "\n",
    "            final_parameters[ind][\"estimate\"] = np.clip(\n",
    "                final_parameters[ind][\"estimate\"] + grad, *final_parameters[ind][\"range\"]\n",
    "            )\n",
    "            \n",
    "    parameters = final_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "50256c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6540584395785568"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4a3eb22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6378155281580116"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_function(X, y, final_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "14d3a980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parameter': 'n_estimators',\n",
       "  'type': 'integer',\n",
       "  'estimate': 83,\n",
       "  'range': [50, 150],\n",
       "  'step': 10,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'criterion',\n",
       "  'type': 'categorical',\n",
       "  'estimate': 'entropy',\n",
       "  'range': ['entropy'],\n",
       "  'step': '',\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'max_depth',\n",
       "  'type': 'integer',\n",
       "  'estimate': 13,\n",
       "  'range': [10, 20],\n",
       "  'step': 2,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'min_samples_split',\n",
       "  'type': 'integer',\n",
       "  'estimate': 6,\n",
       "  'range': [2, 6],\n",
       "  'step': 1,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'min_samples_leaf',\n",
       "  'type': 'integer',\n",
       "  'estimate': 4,\n",
       "  'range': [1, 4],\n",
       "  'step': 1,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'min_weight_fraction_leaf',\n",
       "  'type': 'real',\n",
       "  'estimate': 84.0,\n",
       "  'range': [0.0, 0.5],\n",
       "  'step': 0.05,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'max_features',\n",
       "  'type': 'real',\n",
       "  'estimate': 0.9886724585380823,\n",
       "  'range': [0.5, 1.0],\n",
       "  'step': 0.05,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'z_score',\n",
       "  'type': 'real',\n",
       "  'estimate': 3.813401418088005,\n",
       "  'range': [2.5, 10],\n",
       "  'step': 0.2,\n",
       "  'description': 'preprocessing'},\n",
       " {'parameter': 'min_correlation',\n",
       "  'type': 'real',\n",
       "  'estimate': 0.04565309006023782,\n",
       "  'range': [0.0, 0.2],\n",
       "  'step': 0.005,\n",
       "  'description': 'preprocessing'}]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4dcd7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9fc4b3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parameter': 'n_estimators',\n",
       "  'type': 'integer',\n",
       "  'estimate': 84,\n",
       "  'range': [50, 150],\n",
       "  'step': 10,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'criterion',\n",
       "  'type': 'categorical',\n",
       "  'estimate': 'entropy',\n",
       "  'range': ['entropy'],\n",
       "  'step': '',\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'max_depth',\n",
       "  'type': 'integer',\n",
       "  'estimate': 13,\n",
       "  'range': [10, 20],\n",
       "  'step': 2,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'min_samples_split',\n",
       "  'type': 'integer',\n",
       "  'estimate': 6,\n",
       "  'range': [2, 6],\n",
       "  'step': 1,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'min_samples_leaf',\n",
       "  'type': 'integer',\n",
       "  'estimate': 4,\n",
       "  'range': [1, 4],\n",
       "  'step': 1,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'min_weight_fraction_leaf',\n",
       "  'type': 'real',\n",
       "  'estimate': 0.0,\n",
       "  'range': [0.0, 0.5],\n",
       "  'step': 0.05,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'max_features',\n",
       "  'type': 'real',\n",
       "  'estimate': 0.9886724585380823,\n",
       "  'range': [0.5, 1.0],\n",
       "  'step': 0.05,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'z_score',\n",
       "  'type': 'real',\n",
       "  'estimate': 3.813401418088005,\n",
       "  'range': [2.5, 10],\n",
       "  'step': 0.2,\n",
       "  'description': 'preprocessing'},\n",
       " {'parameter': 'min_correlation',\n",
       "  'type': 'real',\n",
       "  'estimate': 0.04565309006023782,\n",
       "  'range': [0.0, 0.2],\n",
       "  'step': 0.005,\n",
       "  'description': 'preprocessing'}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97ec147f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parameter': 'n_estimators',\n",
       "  'type': 'integer',\n",
       "  'estimate': 83,\n",
       "  'range': [50, 150],\n",
       "  'step': 10,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'criterion',\n",
       "  'type': 'categorical',\n",
       "  'estimate': 'entropy',\n",
       "  'range': ['entropy'],\n",
       "  'step': '',\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'max_depth',\n",
       "  'type': 'integer',\n",
       "  'estimate': 13,\n",
       "  'range': [10, 20],\n",
       "  'step': 2,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'min_samples_split',\n",
       "  'type': 'integer',\n",
       "  'estimate': 6,\n",
       "  'range': [2, 6],\n",
       "  'step': 1,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'min_samples_leaf',\n",
       "  'type': 'integer',\n",
       "  'estimate': 4,\n",
       "  'range': [1, 4],\n",
       "  'step': 1,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'min_weight_fraction_leaf',\n",
       "  'type': 'real',\n",
       "  'estimate': 0.0,\n",
       "  'range': [0.0, 0.5],\n",
       "  'step': 0.05,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'max_features',\n",
       "  'type': 'real',\n",
       "  'estimate': 0.9886724585380823,\n",
       "  'range': [0.5, 1.0],\n",
       "  'step': 0.05,\n",
       "  'description': 'classifier'},\n",
       " {'parameter': 'z_score',\n",
       "  'type': 'real',\n",
       "  'estimate': 3.813401418088005,\n",
       "  'range': [2.5, 10],\n",
       "  'step': 0.2,\n",
       "  'description': 'preprocessing'},\n",
       " {'parameter': 'min_correlation',\n",
       "  'type': 'real',\n",
       "  'estimate': 0.04565309006023782,\n",
       "  'range': [0.0, 0.2],\n",
       "  'step': 0.005,\n",
       "  'description': 'preprocessing'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56e90f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your codes .... \n",
    "\n",
    "\n",
    "best = [5.7600e-02 1.4700e+02 5.0000e+00 2.0000e+00 3.8630e-01 2.1940e-01\n",
    " 7.1780e-01 4.4040e-01 6.5700e-01 3.0000e+00 3.0000e+00 2.6304e+00\n",
    " 0.0000e+00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8612c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Parâmetros\n",
    "with open(r\"parameters_opt.json\", \"r\") as read_file:\n",
    "    parameters = json.load(read_file)\n",
    "\n",
    "X = train.drop(\"y\", 1)\n",
    "y = train[\"y\"]\n",
    "    \n",
    "model = model_instance(parameters)\n",
    "\n",
    "# model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d8364ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6424393785551729"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cross_validate_score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768804fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ec02769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>var10</th>\n",
       "      <th>var11</th>\n",
       "      <th>var12</th>\n",
       "      <th>var13</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>var17</th>\n",
       "      <th>var18</th>\n",
       "      <th>var19</th>\n",
       "      <th>var20</th>\n",
       "      <th>var21</th>\n",
       "      <th>var22</th>\n",
       "      <th>var23</th>\n",
       "      <th>var24</th>\n",
       "      <th>var25</th>\n",
       "      <th>var26</th>\n",
       "      <th>var27</th>\n",
       "      <th>var28</th>\n",
       "      <th>var29</th>\n",
       "      <th>var30</th>\n",
       "      <th>var31</th>\n",
       "      <th>var32</th>\n",
       "      <th>var33</th>\n",
       "      <th>var34</th>\n",
       "      <th>var35</th>\n",
       "      <th>var36</th>\n",
       "      <th>var37</th>\n",
       "      <th>var38</th>\n",
       "      <th>var39</th>\n",
       "      <th>var40</th>\n",
       "      <th>var41</th>\n",
       "      <th>var42</th>\n",
       "      <th>var43</th>\n",
       "      <th>var44</th>\n",
       "      <th>var45</th>\n",
       "      <th>var46</th>\n",
       "      <th>var47</th>\n",
       "      <th>var48</th>\n",
       "      <th>var49</th>\n",
       "      <th>var50</th>\n",
       "      <th>var51</th>\n",
       "      <th>var52</th>\n",
       "      <th>var53</th>\n",
       "      <th>var54</th>\n",
       "      <th>var55</th>\n",
       "      <th>var56</th>\n",
       "      <th>var57</th>\n",
       "      <th>var58</th>\n",
       "      <th>var59</th>\n",
       "      <th>var60</th>\n",
       "      <th>var61</th>\n",
       "      <th>var62</th>\n",
       "      <th>var63</th>\n",
       "      <th>var64</th>\n",
       "      <th>var65</th>\n",
       "      <th>var66</th>\n",
       "      <th>var67</th>\n",
       "      <th>var68</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>1353</td>\n",
       "      <td>28956</td>\n",
       "      <td>743</td>\n",
       "      <td>1289</td>\n",
       "      <td>27</td>\n",
       "      <td>-999</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4530</td>\n",
       "      <td>914</td>\n",
       "      <td>991</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1155</td>\n",
       "      <td>19</td>\n",
       "      <td>1031</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>413</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217528</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.367742</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.201839</td>\n",
       "      <td>0.353965</td>\n",
       "      <td>0.166641</td>\n",
       "      <td>0.049108</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.016683</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.253676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>1446</td>\n",
       "      <td>7803</td>\n",
       "      <td>5151</td>\n",
       "      <td>935</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>8731</td>\n",
       "      <td>1341</td>\n",
       "      <td>2033</td>\n",
       "      <td>26</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>1299</td>\n",
       "      <td>26</td>\n",
       "      <td>773</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>692</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221968</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.177047</td>\n",
       "      <td>0.072127</td>\n",
       "      <td>0.074555</td>\n",
       "      <td>0.217009</td>\n",
       "      <td>0.144403</td>\n",
       "      <td>0.892028</td>\n",
       "      <td>0.038323</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.099265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>243</td>\n",
       "      <td>4325</td>\n",
       "      <td>1109</td>\n",
       "      <td>1903</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>10131</td>\n",
       "      <td>914</td>\n",
       "      <td>1503</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>1294</td>\n",
       "      <td>24</td>\n",
       "      <td>1562</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>553</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.213224</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.101075</td>\n",
       "      <td>0.210879</td>\n",
       "      <td>0.324770</td>\n",
       "      <td>0.384992</td>\n",
       "      <td>0.330680</td>\n",
       "      <td>0.072864</td>\n",
       "      <td>0.930373</td>\n",
       "      <td>0.021052</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.136029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>419</td>\n",
       "      <td>743</td>\n",
       "      <td>7750</td>\n",
       "      <td>183</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>636</td>\n",
       "      <td>5879</td>\n",
       "      <td>146</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>811</td>\n",
       "      <td>26</td>\n",
       "      <td>152</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>662</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.205044</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.131070</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.244936</td>\n",
       "      <td>0.158088</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.220588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>1863</td>\n",
       "      <td>22693</td>\n",
       "      <td>5625</td>\n",
       "      <td>965</td>\n",
       "      <td>9</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>24967</td>\n",
       "      <td>4427</td>\n",
       "      <td>772</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.024989</td>\n",
       "      <td>0.225166</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>0.252794</td>\n",
       "      <td>0.080405</td>\n",
       "      <td>0.944501</td>\n",
       "      <td>0.021806</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.113971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35297</th>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>1460</td>\n",
       "      <td>13335</td>\n",
       "      <td>9048</td>\n",
       "      <td>620</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>13567</td>\n",
       "      <td>2617</td>\n",
       "      <td>572</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1573</td>\n",
       "      <td>26</td>\n",
       "      <td>592</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>332</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.213106</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.387701</td>\n",
       "      <td>0.148933</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.326307</td>\n",
       "      <td>0.132833</td>\n",
       "      <td>0.968718</td>\n",
       "      <td>0.039626</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.253676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35298</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>532</td>\n",
       "      <td>14837</td>\n",
       "      <td>2590</td>\n",
       "      <td>855</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>15367</td>\n",
       "      <td>2261</td>\n",
       "      <td>678</td>\n",
       "      <td>19</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>1383</td>\n",
       "      <td>19</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>578</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.210435</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.101075</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.179243</td>\n",
       "      <td>0.205030</td>\n",
       "      <td>0.229354</td>\n",
       "      <td>0.052108</td>\n",
       "      <td>0.940464</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.209559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35300</th>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>2923</td>\n",
       "      <td>16685</td>\n",
       "      <td>3162</td>\n",
       "      <td>1604</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>17658</td>\n",
       "      <td>4369</td>\n",
       "      <td>1279</td>\n",
       "      <td>26</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>971</td>\n",
       "      <td>26</td>\n",
       "      <td>1334</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>74</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.218353</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.367742</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.237607</td>\n",
       "      <td>0.810448</td>\n",
       "      <td>0.179781</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>0.745711</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.161765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35302</th>\n",
       "      <td>5</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>367</td>\n",
       "      <td>7637</td>\n",
       "      <td>1389</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>28370</td>\n",
       "      <td>679</td>\n",
       "      <td>1117</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>868</td>\n",
       "      <td>26</td>\n",
       "      <td>1158</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.224865</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.246237</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.102662</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.149598</td>\n",
       "      <td>0.032583</td>\n",
       "      <td>0.891019</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.246324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35303</th>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>1446</td>\n",
       "      <td>6031</td>\n",
       "      <td>853</td>\n",
       "      <td>829</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3182</td>\n",
       "      <td>5360</td>\n",
       "      <td>1910</td>\n",
       "      <td>26</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1473</td>\n",
       "      <td>26</td>\n",
       "      <td>675</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>89</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.207270</td>\n",
       "      <td>0.031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020069</td>\n",
       "      <td>0.313769</td>\n",
       "      <td>0.092545</td>\n",
       "      <td>0.285876</td>\n",
       "      <td>0.079940</td>\n",
       "      <td>0.901110</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21183 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1  var2  var3   var4  var5  var6  var7  var8  var9  var10  var11  \\\n",
       "id                                                                           \n",
       "0         5   126  1353  28956   743  1289    27  -999     1     33   4530   \n",
       "2         6   126  1446   7803  5151   935    35  -999     3     63   8731   \n",
       "4         5    44   243   4325  1109  1903    33    24     1     63  10131   \n",
       "7         4    53   419    743  7750   183    35  -999     3     14    636   \n",
       "15        4   126  1863  22693  5625   965     9  -999     3     63  24967   \n",
       "...     ...   ...   ...    ...   ...   ...   ...   ...   ...    ...    ...   \n",
       "35297     4   126  1460  13335  9048   620    35    27     3     63  13567   \n",
       "35298    18    19   532  14837  2590   855    27    20     3     63  15367   \n",
       "35300     4   126  2923  16685  3162  1604    35  -999     3     63  17658   \n",
       "35302     5  -999  -999    367  7637  1389    35  -999     3     63  28370   \n",
       "35303     6   126  1446   6031   853   829    35    27     3     14   3182   \n",
       "\n",
       "       var12  var13  var14  var15  var16  var17  var18  var19  var20  var21  \\\n",
       "id                                                                            \n",
       "0        914    991     19      1      3      3      3   1155     19   1031   \n",
       "2       1341   2033     26     58     58     22      5   1299     26    773   \n",
       "4        914   1503     24     60     61     23      5   1294     24   1562   \n",
       "7       5879    146     26     22     22     10      4    811     26    152   \n",
       "15      4427    772      5     73     73     29      5    595      5    796   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "35297   2617    572     26     37     35     11      4   1573     26    592   \n",
       "35298   2261    678     19   -999   -999   -999   -999   1383     19    700   \n",
       "35300   4369   1279     26   -999   -999   -999   -999    971     26   1334   \n",
       "35302    679   1117     26     34     34     10      4    868     26   1158   \n",
       "35303   5360   1910     26     55     56     20      5   1473     26    675   \n",
       "\n",
       "       var22  var23  var24  var25  var26  var27  var28  var29  var30  var31  \\\n",
       "id                                                                            \n",
       "0          5      3      2      3      7      0     25      4      1      0   \n",
       "2          5      3      1      2      1      0     25      4      0      1   \n",
       "4          5      4      1      0      1      0     26      5      2      0   \n",
       "7          5      3      2      4      4      0     24      4      2      0   \n",
       "15         0      1      0      1      7      0     11      2      1      0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "35297      5      3      2      1      1      0     24      4      1      0   \n",
       "35298      0      3      2      1   -999      0     25      4      1      0   \n",
       "35300      5      3      0      1   -999      0     24      4      1      0   \n",
       "35302      5      3      2      1      9      0     24      4      1      0   \n",
       "35303      5      3      2      1      7      1     24      4      1      0   \n",
       "\n",
       "       var32  var33  var34  var35  var36  var37  var38  var39  var40  var41  \\\n",
       "id                                                                            \n",
       "0         11      2     62    413     27      0      0      4      6      3   \n",
       "2          6      5     58    692     21     15      8      4      0      1   \n",
       "4         17      0     12    553      0     18      0      4     10      3   \n",
       "7         12      5     38    662     28      1      0      4      9      3   \n",
       "15        21      3     18    546      0      1      0      4      6      3   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "35297     21      6     42    332     21     20      9      1     11      3   \n",
       "35298     20      0     60    578      2      0      0      4      2      3   \n",
       "35300     12      5     49     74     28      2      0      4      4      3   \n",
       "35302     15      5     54    434      0      1      0      4     19      3   \n",
       "35303     15      6     33     89     31      4      0      4     16      3   \n",
       "\n",
       "       var42  var43  var44  var45  var46  var47  var48  var49  var50  var51  \\\n",
       "id                                                                            \n",
       "0         24      3      1      0      0      0      0      0      0      0   \n",
       "2         30      0      1      0      0      0      0      0      0      0   \n",
       "4         26     14      1      0      0      0      0      0      0      0   \n",
       "7         28      7      1      0      0      0      0      0      1      0   \n",
       "15        28      8      1      0      0      0      0      1      0      0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "35297     25     13      1      0      0      0      0      0      0      0   \n",
       "35298     26      6      1      0      0      0      0      0      0      0   \n",
       "35300     19      4      1      0      0      0      0      0      0      0   \n",
       "35302     23      6      1      0      0      0      0      0      0      0   \n",
       "35303     22     11      1      0      0      0      0      0      0      0   \n",
       "\n",
       "       var52  var53  var54     var55  var56     var57       var58     var59  \\\n",
       "id                                                                            \n",
       "0         44      1      1  0.217528  0.272  0.367742    0.062900  0.201839   \n",
       "2         13      1      1  0.221968  0.853  0.053763    0.177047  0.072127   \n",
       "4         36      1      1  0.213224  0.632  0.101075    0.210879  0.324770   \n",
       "7         13      1      1  0.205044  0.117  0.935484    0.007068  0.131070   \n",
       "15        51      1      1  0.203750  0.079  0.967742    0.024989  0.225166   \n",
       "...      ...    ...    ...       ...    ...       ...         ...       ...   \n",
       "35297     34      2      2  0.213106  0.065  0.967742    0.387701  0.148933   \n",
       "35298     10      2      2  0.210435  0.740  0.101075 -999.000000  0.179243   \n",
       "35300     39      2      2  0.218353  0.288  0.367742 -999.000000  0.237607   \n",
       "35302      3      2      2  0.224865  0.324  0.246237    0.199008  0.102662   \n",
       "35303     19      2      2  0.207270  0.031  1.000000    0.020069  0.313769   \n",
       "\n",
       "            var60     var61     var62     var63     var64  var65  var66  \\\n",
       "id                                                                        \n",
       "0        0.353965  0.166641  0.049108  0.986882  0.016683 -999.0 -999.0   \n",
       "2        0.074555  0.217009  0.144403  0.892028  0.038323 -999.0 -999.0   \n",
       "4        0.384992  0.330680  0.072864  0.930373  0.021052 -999.0 -999.0   \n",
       "7     -999.000000  0.244936  0.158088  0.986882  0.022649 -999.0 -999.0   \n",
       "15       0.059940  0.252794  0.080405  0.944501  0.021806 -999.0 -999.0   \n",
       "...           ...       ...       ...       ...       ...    ...    ...   \n",
       "35297 -999.000000  0.326307  0.132833  0.968718  0.039626 -999.0 -999.0   \n",
       "35298    0.205030  0.229354  0.052108  0.940464  0.016952 -999.0 -999.0   \n",
       "35300    0.810448  0.179781  0.029155  0.745711  0.020158 -999.0 -999.0   \n",
       "35302 -999.000000  0.149598  0.032583  0.891019  0.012596 -999.0 -999.0   \n",
       "35303    0.092545  0.285876  0.079940  0.901110  0.026239 -999.0 -999.0   \n",
       "\n",
       "            var67     var68  \n",
       "id                           \n",
       "0        0.176471  0.253676  \n",
       "2        0.147059  0.099265  \n",
       "4        0.294118  0.136029  \n",
       "7        0.294118  0.220588  \n",
       "15       0.352941  0.113971  \n",
       "...           ...       ...  \n",
       "35297    0.323529  0.253676  \n",
       "35298    0.088235  0.209559  \n",
       "35300    0.205882  0.161765  \n",
       "35302 -999.000000  0.246324  \n",
       "35303    0.191176  0.312500  \n",
       "\n",
       "[21183 rows x 68 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9cc2fa",
   "metadata": {},
   "source": [
    "## Exportando testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b4d5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"submission-14.csv\").drop(\"predicted\", 1).assign(\n",
    "    predicted=model.predict(test)\n",
    ").to_csv(\"submission-15.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14608500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21178</th>\n",
       "      <td>35297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21179</th>\n",
       "      <td>35298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21180</th>\n",
       "      <td>35300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21181</th>\n",
       "      <td>35302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21182</th>\n",
       "      <td>35303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  predicted\n",
       "0          0          1\n",
       "1          2          1\n",
       "2          4          0\n",
       "3          7          1\n",
       "4         15          0\n",
       "...      ...        ...\n",
       "21178  35297          0\n",
       "21179  35298          0\n",
       "21180  35300          1\n",
       "21181  35302          1\n",
       "21182  35303          0\n",
       "\n",
       "[21183 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission-14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "430a09d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21178</th>\n",
       "      <td>35297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21179</th>\n",
       "      <td>35298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21180</th>\n",
       "      <td>35300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21181</th>\n",
       "      <td>35302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21182</th>\n",
       "      <td>35303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  predicted\n",
       "0          0          1\n",
       "1          2          1\n",
       "2          4          0\n",
       "3          7          0\n",
       "4         15          0\n",
       "...      ...        ...\n",
       "21178  35297          0\n",
       "21179  35298          0\n",
       "21180  35300          1\n",
       "21181  35302          0\n",
       "21182  35303          0\n",
       "\n",
       "[21183 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission-15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59851a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_stratified_folds(train, n_folds=5, shuffle=True, random_state=42):\n",
    "\n",
    "#     temp = train.copy().reset_index(drop=True)\n",
    "\n",
    "#     # Instaciando o estritificador\n",
    "#     skf = StratifiedKFold(n_splits=n_folds, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "#     # Gerando os index com os folds\n",
    "#     stratified_folds = list(skf.split(X=temp.drop(columns=\"y\"), y=temp[\"y\"]))\n",
    "\n",
    "#     for fold_index in range(n_folds):\n",
    "\n",
    "#         train_index, validation_index = stratified_folds[fold_index]\n",
    "\n",
    "#         temp.loc[temp[temp.index.isin(validation_index)].index, \"fold\"] = fold_index\n",
    "\n",
    "#     return temp[\"fold\"].astype(int)\n",
    "\n",
    "\n",
    "# def cross_validate_score(\n",
    "#     X,\n",
    "#     y,\n",
    "#     estimator,\n",
    "#     n_folds=5,\n",
    "#     scoring=f1_score,\n",
    "#     threshold=0.3,\n",
    "#     random_state=42,\n",
    "#     verbose=0,\n",
    "#     fit_params={},\n",
    "# ):\n",
    "\n",
    "#     scores = []\n",
    "\n",
    "#     temp = X.assign(y=y)\n",
    "\n",
    "#     temp[\"fold\"] = generate_stratified_folds(temp, n_folds=n_folds)\n",
    "\n",
    "#     iterator = (\n",
    "#         range(n_folds) if verbose < 1 else tqdm(range(n_folds), desc=\"Cross validation\")\n",
    "#     )\n",
    "\n",
    "#     for fold in iterator:\n",
    "\n",
    "#         # Separando os dados de treinamento para essa fold\n",
    "#         train_data = temp[temp[\"fold\"] != fold].copy()\n",
    "\n",
    "#         # Separando os dados de teste para esse fold\n",
    "#         test_data = temp[temp[\"fold\"] == fold].copy()\n",
    "\n",
    "#         X_train = train_data.drop(columns=[\"fold\", \"y\"]).values\n",
    "\n",
    "#         X_test = test_data.drop(columns=[\"fold\", \"y\"]).values\n",
    "\n",
    "#         y_train = train_data[\"y\"].values\n",
    "\n",
    "#         y_test = test_data[\"y\"].values\n",
    "\n",
    "#         if estimator.__class__ == xgboost.sklearn.XGBClassifier:\n",
    "#             fit_params[\"eval_set\"] = [(X_test, y_test)]\n",
    "\n",
    "#         try:\n",
    "#             estimator.fit(X_train, y_train, verbose=0, **fit_params)\n",
    "#         except:\n",
    "#             estimator.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "#         prob_test = estimator.predict_proba(X_test)[:, -1]\n",
    "\n",
    "#         scores.append(scoring(y_test, prob_test > threshold))\n",
    "\n",
    "#     avg_score = np.mean(scores)\n",
    "\n",
    "#     return -avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab245e1",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32c166d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b91ec7f1",
   "metadata": {},
   "source": [
    "Funcoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff51dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "\n",
    "\n",
    "# class PolynomialFeatures(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, degree=2, include_bias=True, **kwargs):\n",
    "#         self.kwargs = kwargs\n",
    "#         self.degree = degree\n",
    "#         self.include_bias = include_bias\n",
    "#         self.columns = None\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         self.columns = X.columns\n",
    "#         self.poly_feat = sklearn.preprocessing.PolynomialFeatures(\n",
    "#             degree=self.degree, include_bias=self.include_bias, **self.kwargs\n",
    "#         ).fit(X, y)\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "        \n",
    "#         if self.include_bias:\n",
    "#             cols = ['bias']\n",
    "#         else:\n",
    "#             cols = []\n",
    "            \n",
    "#         for i in range(1, 1 + self.degree):\n",
    "#             cols = cols + [\n",
    "#                 \"*\".join(e)\n",
    "#                 for e in list(combinations_with_replacement(self.columns, i))\n",
    "#             ]\n",
    "\n",
    "#         # Dados transformados\n",
    "#         X_transf = pd.DataFrame(\n",
    "#             self.poly_feat.transform(X), columns=cols, index=X.index\n",
    "#         )\n",
    "\n",
    "#         return X_transf\n",
    "\n",
    "#     def fit_transform(self, X, y=None):\n",
    "#         self.fit(X)\n",
    "#         return self.transform(X)\n",
    "\n",
    "\n",
    "# # PolynomialFeatures().fit_transform(X.iloc[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88f557c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.base import TransformerMixin, BaseEstimator\n",
    "# from xtlearn.preprocessing import MinMaxScaler\n",
    "# from copy import deepcopy\n",
    "# from xtlearn.feature_selection import FeatureSelector\n",
    "\n",
    "\n",
    "# def dataframe_transform(data, transformer):\n",
    "#     return pd.DataFrame(\n",
    "#         transformer.transform(data), columns=data.columns, index=data.index\n",
    "#     )\n",
    "\n",
    "\n",
    "# class Model(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         classifier,\n",
    "#         classifier_params={},\n",
    "#         min_correlation=0.0,\n",
    "#         z_score_range=None,\n",
    "#         polynomial_degree=1,\n",
    "#     ):\n",
    "\n",
    "#         self.classifier = classifier\n",
    "#         self.classifier_params = classifier_params\n",
    "#         self.min_correlation = min_correlation\n",
    "#         self.z_score_range = z_score_range\n",
    "#         self.polynomial_degree = polynomial_degree\n",
    "\n",
    "#         self.set_classifier_params(**classifier_params)\n",
    "#         self.corr_columns = None\n",
    "#         self.selected_columns = None\n",
    "#         self.preprocessing = None\n",
    "\n",
    "#     def fit(self, X, y=None, fit_params={}):\n",
    "\n",
    "#         # Gerando cópias\n",
    "#         X = X.copy()\n",
    "#         y = y.copy()\n",
    "\n",
    "#         # Coletando informações\n",
    "#         self.corr_columns = (\n",
    "#             X.assign(y=y).corr()[\"y\"].drop(\"y\").abs().sort_values(ascending=False)\n",
    "#         )\n",
    "        \n",
    "#         # Encontrando as colunas com uma corr mínima\n",
    "#         self.selected_columns = self.corr_columns[\n",
    "#             self.corr_columns > self.min_correlation\n",
    "#         ].index\n",
    "\n",
    "\n",
    "#         # Definindo os limites de zscore\n",
    "#         if self.z_score_range is None:\n",
    "#             min_z, max_z = (-1000, 1000)\n",
    "#         else:\n",
    "#             min_z, max_z = self.z_score_range\n",
    "\n",
    "#         # Pipeline de preprocessamento\n",
    "#         self.preprocessing = Pipeline(\n",
    "#             steps=[\n",
    "#                 (\"FeatureSelector\", FeatureSelector(self.selected_columns)),\n",
    "#                 (\"ZClipper\", ZClipper(min_z=min_z, max_z=max_z)),\n",
    "#                 (\"Correlatum\", Correlatum()),\n",
    "#                 (\"Imputer\", Imputer()),\n",
    "#                 (\"MinMaxScaler\", MinMaxScaler()),\n",
    "#                 (\n",
    "#                     \"PolynomialFeatures\",\n",
    "#                     PolynomialFeatures(\n",
    "#                         degree=self.polynomial_degree, include_bias=False\n",
    "#                     ),\n",
    "#                 ),\n",
    "#             ]\n",
    "#         )\n",
    "        \n",
    "#         # Treinando o preprocessamento\n",
    "#         self.preprocessing.fit(X, y)\n",
    "        \n",
    "#         # Aplicando a transformação\n",
    "#         X = self.transform(X, y)\n",
    "\n",
    "#         # Fitar o classificador\n",
    "#         self.classifier.set_params(**self.classifier_params)\n",
    "\n",
    "#         # Fitar\n",
    "#         self.classifier.fit(X, y, **fit_params)\n",
    "\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "\n",
    "#         X = X.copy()\n",
    "\n",
    "#         if y is not None:\n",
    "#             y = y.copy()\n",
    "\n",
    "#         return self.preprocessing.transform(X)\n",
    "\n",
    "#     def predict(self, X, threshold=0.5):\n",
    "#         X = X.copy()\n",
    "#         X = self.transform(X, y=None)\n",
    "#         predict_prob = self.classifier.predict_proba(X)[:, 1]\n",
    "#         condition = lambda x: x > threshold\n",
    "#         vec_condition = np.vectorize(condition)\n",
    "#         return np.where(vec_condition(predict_prob), 1, 0)\n",
    "\n",
    "#     def predict_proba(self, X):\n",
    "#         X = X.copy()\n",
    "#         X = self.transform(X, y=None)\n",
    "#         return self.classifier.predict_proba(X)[:, 1]\n",
    "\n",
    "#     def set_classifier_params(self, **classifier_params):\n",
    "#         self.classifier.set_params(**classifier_params)\n",
    "\n",
    "#     def cross_validate_score(\n",
    "#         self,\n",
    "#         X,\n",
    "#         y,\n",
    "#         n_folds=5,\n",
    "#         threshold=0.3,\n",
    "#         random_state=42,\n",
    "#         verbose=0,\n",
    "#         fit_params={},\n",
    "#     ):\n",
    "#         X = X.copy()\n",
    "#         y = y.copy()\n",
    "\n",
    "#         self.fit(X, y)\n",
    "        \n",
    "#         X = self.transform(X, y)\n",
    "\n",
    "#         return cross_validate_score(\n",
    "#             X=X,\n",
    "#             y=y,\n",
    "#             estimator=self.classifier,\n",
    "#             n_folds=n_folds,\n",
    "#             scoring=f1_score,\n",
    "#             threshold=threshold,\n",
    "#             random_state=random_state,\n",
    "#             verbose=verbose,\n",
    "#             fit_params={},\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89acef0",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4450099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from itertools import product, combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71476df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        \"parameter\": \"learning_rate\",\n",
    "        \"type\": \"real\",\n",
    "        \"estimate\": 0.091,\n",
    "        \"range\": (0.05,1.13),\n",
    "        \"step\": 0.01,\n",
    "        \"description\": \"classifier\",\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"n_estimators\",\n",
    "        \"type\": \"integer\",\n",
    "        \"estimate\": 150,\n",
    "        \"range\": (140,160),\n",
    "        \"step\": 1,\n",
    "        \"description\": \"classifier\",\n",
    "        \"desc\": \"classifier\"\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"max_depth\",\n",
    "        \"type\": \"integer\",\n",
    "        \"estimate\": 4,\n",
    "        \"range\": (3,5),\n",
    "        \"step\": 1,\n",
    "        \"description\": \"classifier\",\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"min_child_weight\",\n",
    "        \"type\": \"integer\",\n",
    "        \"estimate\": 2,\n",
    "        \"range\": (1.5,2.5),\n",
    "        \"step\": 0.4,\n",
    "        \"description\": \"classifier\",\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"subsample\",\n",
    "        \"type\": \"real\",\n",
    "        \"estimate\": 0.4,\n",
    "        \"range\": (0.35,0.45),\n",
    "        \"step\": 0.01,\n",
    "        \"description\": \"classifier\",\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"reg_alpha\",\n",
    "        \"type\": \"real\",\n",
    "        \"estimate\": 0.2,\n",
    "        \"range\": (0.0,1.0),\n",
    "        \"step\": 0.01,\n",
    "        \"description\": \"classifier\",\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"reg_lambda\",\n",
    "        \"type\": \"real\",\n",
    "        \"estimate\": 0.7,\n",
    "        \"range\": (0.0,1.0),\n",
    "        \"step\": 0.01,\n",
    "        \"description\": \"classifier\",\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"colsample_bynode\",\n",
    "        \"type\": \"real\",\n",
    "        \"estimate\": 0.4,\n",
    "        \"range\": (0.0,1.0),\n",
    "        \"step\": 0.01,\n",
    "        \"description\": \"classifier\",\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"colsample_bytree\",\n",
    "        \"type\": \"real\",\n",
    "        \"estimate\": 0.6,\n",
    "        \"range\": (0.0,1.0),\n",
    "        \"step\": 0.01,\n",
    "        \"description\": \"classifier\",\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"num_parallel_tree\",\n",
    "        \"type\": \"integer\",\n",
    "        \"estimate\": 3,\n",
    "        \"range\": (1,4),\n",
    "        \"step\": 1,\n",
    "        \"description\": \"classifier\",\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"max_delta_step\",\n",
    "        \"type\": \"integer\",\n",
    "        \"estimate\": 3,\n",
    "        \"range\": (1,4),\n",
    "        \"step\": 1,\n",
    "        \"description\": \"classifier\",\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"z_score\",\n",
    "        \"type\": \"real\",\n",
    "        \"estimate\": 3,\n",
    "        \"range\": (2.5,10),\n",
    "        \"step\": 0.2,\n",
    "        \"description\": \"preprocessing\",\n",
    "    },\n",
    "    {\n",
    "        \"parameter\": \"min_correlation\",\n",
    "        \"type\": \"real\",\n",
    "        \"estimate\": 0.02,\n",
    "        \"range\": (0.0,0.2),\n",
    "        \"step\": 0.005,\n",
    "        \"description\": \"preprocessing\",\n",
    "    },\n",
    "]\n",
    "\n",
    "with open('parameters.json', 'w') as file:\n",
    "    json.dump(parameters,file,indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e3fbd26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run experimental.py\n",
    "\n",
    "# Importando Parâmetros\n",
    "with open(r\"parameters.json\", \"r\") as read_file:\n",
    "    parameters = json.load(read_file)\n",
    "    \n",
    "    \n",
    "new_parameters(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e847c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copy import deepcopy\n",
    "# import numpy as np\n",
    "\n",
    "# def new_parameters(parameters):\n",
    "\n",
    "#     new_parameters = deepcopy(parameters)\n",
    "\n",
    "#     for elem in new_parameters:\n",
    "#         if elem[\"type\"] == \"real\":\n",
    "#             elem[\"estimate\"] = elem[\"estimate\"] + np.random.uniform(\n",
    "#                 -elem[\"step\"], elem[\"step\"]\n",
    "#             )\n",
    "#             elem[\"estimate\"] = np.clip(elem[\"estimate\"], *elem[\"range\"])\n",
    "\n",
    "#         elif elem[\"type\"] == \"integer\":\n",
    "#             elem[\"estimate\"] = elem[\"estimate\"] + int(\n",
    "#                 np.round(np.random.uniform(-elem[\"step\"], elem[\"step\"]), 0)\n",
    "#             )\n",
    "#             elem[\"estimate\"] = np.clip(elem[\"estimate\"], *elem[\"range\"])\n",
    "\n",
    "#         elif elem[\"type\"] == \"categorical\":\n",
    "#             elem[\"estimate\"] = np.random.choice(elem[\"range\"])\n",
    "\n",
    "#     return new_parameters\n",
    "\n",
    "# new_parameters(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b924bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac351480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.670192813380508"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa9bb37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.0, 3.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07344503",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBClassifier(n_jobs=n_jobs, random_state=42, eval_metric=\"logloss\")\n",
    "\n",
    "model = Model(\n",
    "    estimator,\n",
    "    classifier_params=classifier_parameters,\n",
    "    min_correlation=min_correlation,\n",
    "    z_score_range=z_score_range,\n",
    "    polynomial_degree=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bf7ff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(classifier=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=0.4,\n",
       "                               colsample_bytree=0.6, eval_metric='logloss',\n",
       "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.091,\n",
       "                               max_delta_step=3, max_depth=4,\n",
       "                               min_child_weight=2, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=150,\n",
       "                               n_jobs=4, num...\n",
       "                               scale_pos_weight=1, subsample=0.4,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None),\n",
       "      classifier_params={'colsample_bynode': 0.4, 'colsample_bytree': 0.6,\n",
       "                         'learning_rate': 0.091, 'max_delta_step': 3,\n",
       "                         'max_depth': 4, 'min_child_weight': 2,\n",
       "                         'n_estimators': 150, 'num_parallel_tree': 3,\n",
       "                         'reg_alpha': 0.2, 'reg_lambda': 0.7,\n",
       "                         'subsample': 0.4},\n",
       "      min_correlation=0.02, z_score_range=(-3.0, 3.0))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a6e1c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.670192813380508"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cross_validate_score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b24f1615",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2395f03b8438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m }\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/optimization_pipeline.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import gp_minimize\n",
    "\n",
    "steps = {\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"n_estimators\": 5,\n",
    "    \"max_depth\": 1,\n",
    "    \"subsample\": 0.005,\n",
    "    \"min_child_weight\": 0.05,\n",
    "    \"reg_alpha\": 0.005,\n",
    "    \"reg_lambda\": 0.005,\n",
    "    \"colsample_bynode\": 0.005,\n",
    "    \"colsample_bytree\": 0.005,\n",
    "    \"num_parallel_tree\": 1,\n",
    "    \"max_delta_step\": 1,\n",
    "    \"min_correlation\": 0.01,\n",
    "    \"z_score\": 0.05,\n",
    "}\n",
    "\n",
    "# # guardar isso de norte\n",
    "par_0 = {\n",
    "    \"learning_rate\": 0.091,\n",
    "    \"n_estimators\": 150,\n",
    "    \"max_depth\": 4,\n",
    "    \"subsample\": 0.4,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"reg_alpha\": 0.2,\n",
    "    \"reg_lambda\": 0.7,\n",
    "    \"colsample_bynode\": 0.4,\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"num_parallel_tree\": 3,\n",
    "    \"max_delta_step\": 3,\n",
    "    \"min_correlation\": 0.02,\n",
    "    \"z_score\": 3,\n",
    "}\n",
    "\n",
    "results = pd.read_csv(\"../data/optimization_pipeline.csv\").sort_values(\"score\")\n",
    "x0 = list(results.drop([\"iteration\", \"score\"], 1).iloc[0].values)\n",
    "y0 = results[\"score\"].iloc[0]\n",
    "print(y0)\n",
    "par_0 = dict(zip(par_0.keys(), x0))\n",
    "\n",
    "space = [\n",
    "    Real(\n",
    "        par_0[\"learning_rate\"] - steps[\"learning_rate\"],\n",
    "        par_0[\"learning_rate\"] + steps[\"learning_rate\"],\n",
    "        \"log-uniform\",\n",
    "        name=\"learning_rate\",\n",
    "    ),\n",
    "    Integer(\n",
    "        int(par_0[\"n_estimators\"]) - steps[\"n_estimators\"],\n",
    "        int(par_0[\"n_estimators\"]) + steps[\"n_estimators\"],\n",
    "        \"log-uniform\",\n",
    "        name=\"n_estimators\",\n",
    "    ),\n",
    "    Integer(\n",
    "        int(par_0[\"max_depth\"]),\n",
    "        int(par_0[\"max_depth\"] + steps[\"max_depth\"]),\n",
    "        name=\"max_depth\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"subsample\"] - steps[\"subsample\"],\n",
    "        par_0[\"subsample\"] + steps[\"subsample\"],\n",
    "        name=\"subsample\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"min_child_weight\"] - steps[\"min_child_weight\"],\n",
    "        par_0[\"min_child_weight\"] + steps[\"min_child_weight\"],\n",
    "        name=\"min_child_weight\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"reg_alpha\"] - steps[\"reg_alpha\"],\n",
    "        par_0[\"reg_alpha\"] + steps[\"reg_alpha\"],\n",
    "        name=\"reg_alpha\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"reg_lambda\"] - steps[\"reg_lambda\"],\n",
    "        par_0[\"reg_lambda\"] + steps[\"reg_lambda\"],\n",
    "        name=\"reg_lambda\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"colsample_bynode\"] - steps[\"colsample_bynode\"],\n",
    "        par_0[\"colsample_bynode\"] + steps[\"colsample_bynode\"],\n",
    "        name=\"colsample_bynode\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"colsample_bytree\"] - steps[\"colsample_bytree\"],\n",
    "        par_0[\"colsample_bytree\"] + steps[\"colsample_bytree\"],\n",
    "        name=\"colsample_bytree\",\n",
    "    ),\n",
    "    Integer(\n",
    "        int(par_0[\"num_parallel_tree\"]),\n",
    "        int(par_0[\"num_parallel_tree\"] + steps[\"num_parallel_tree\"]),\n",
    "        name=\"num_parallel_tree\",\n",
    "    ),\n",
    "    Integer(\n",
    "        int(par_0[\"max_delta_step\"]),\n",
    "        int(par_0[\"max_delta_step\"] + steps[\"max_delta_step\"]),\n",
    "        name=\"max_delta_step\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"min_correlation\"] - steps[\"min_correlation\"],\n",
    "        par_0[\"min_correlation\"] + steps[\"min_correlation\"],\n",
    "        name=\"min_correlation\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"z_score\"] - steps[\"z_score\"],\n",
    "        par_0[\"z_score\"] + steps[\"z_score\"],\n",
    "        name=\"z_score\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# # guardar isso de norte\n",
    "# par = {\n",
    "#     \"learning_rate\": 0.091,\n",
    "#     \"n_estimators\": 150,\n",
    "#     \"max_depth\": 4,\n",
    "#     \"subsample\": 0.4,\n",
    "#     \"min_child_weight\": 2,\n",
    "#     \"reg_alpha\": 0.2,\n",
    "#     \"reg_lambda\": 0.7,\n",
    "#     \"colsample_bynode\": 0.4,\n",
    "#     \"colsample_bytree\": 0.6,\n",
    "#     \"num_parallel_tree\": 3,\n",
    "#     \"max_delta_step\": 3,\n",
    "# }\n",
    "\n",
    "PARAMETER_NAMES = [elem.name for elem in space]\n",
    "\n",
    "\n",
    "X = train.drop(\"y\", 1)\n",
    "y = train[\"y\"]\n",
    "\n",
    "@use_named_args(space)\n",
    "def train_function(**params):\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # guardar isso de norte\n",
    "    par = {\n",
    "        \"learning_rate\": params[\"learning_rate\"],\n",
    "        \"n_estimators\": params[\"n_estimators\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"subsample\": params[\"subsample\"],\n",
    "        \"min_child_weight\": params[\"min_child_weight\"],\n",
    "        \"reg_alpha\": params[\"reg_alpha\"],\n",
    "        \"reg_lambda\": params[\"reg_lambda\"],\n",
    "        \"colsample_bynode\": params[\"colsample_bynode\"],\n",
    "        \"colsample_bytree\": params[\"colsample_bytree\"],\n",
    "        \"num_parallel_tree\": params[\"num_parallel_tree\"],\n",
    "        \"max_delta_step\": params[\"max_delta_step\"],\n",
    "    }\n",
    "\n",
    "    min_correlation = params[\"min_correlation\"]\n",
    "    z_score = params[\"z_score\"]\n",
    "    z_score_range = (-z_score,z_score)\n",
    "    polynomial_degree = 1\n",
    "\n",
    "    estimator = XGBClassifier(n_jobs=n_jobs, random_state=42, eval_metric=\"logloss\")\n",
    "\n",
    "\n",
    "    model = Model(\n",
    "        estimator,\n",
    "        classifier_params=par,\n",
    "        min_correlation=min_correlation,\n",
    "        z_score_range=z_score_range,\n",
    "        polynomial_degree = polynomial_degree,\n",
    "    )\n",
    "\n",
    "    cv_score = model.cross_validate_score(X,y)\n",
    "    \n",
    "    print(\"\\n\\n >>> Parameters:\",np.round(list(params.values()),3) )\n",
    "    print(\" >>> Score     :\",np.round(cv_score,3),\"\\n\\n\")\n",
    "\n",
    "    return cv_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9a34082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6719604439426176\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 0.0003\n",
      "Function value obtained: -0.6720\n",
      "Current minimum: -0.6720\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "\n",
      "\n",
      " >>> Parameters: [9.400e-02 1.560e+02 6.000e+00 4.120e-01 2.034e+00 2.020e-01 7.000e-01\n",
      " 3.960e-01 6.010e-01 5.000e+00 4.000e+00 3.100e-02 3.025e+00]\n",
      " >>> Score     : -0.668 \n",
      "\n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 49.6546\n",
      "Function value obtained: -0.6681\n",
      "Current minimum: -0.6720\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "\n",
      "\n",
      " >>> Parameters: [9.600e-02 1.510e+02 6.000e+00 4.080e-01 2.068e+00 1.990e-01 7.050e-01\n",
      " 4.000e-01 6.060e-01 6.000e+00 4.000e+00 3.500e-02 3.044e+00]\n",
      " >>> Score     : -0.661 \n",
      "\n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 66.2367\n",
      "Function value obtained: -0.6614\n",
      "Current minimum: -0.6720\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "\n",
      "\n",
      " >>> Parameters: [9.300e-02 1.560e+02 5.000e+00 4.090e-01 1.991e+00 2.050e-01 6.990e-01\n",
      " 3.970e-01 6.010e-01 5.000e+00 3.000e+00 2.900e-02 3.076e+00]\n",
      " >>> Score     : -0.662 \n",
      "\n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 37.3140\n",
      "Function value obtained: -0.6620\n",
      "Current minimum: -0.6720\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "\n",
      "\n",
      " >>> Parameters: [9.200e-02 1.540e+02 6.000e+00 4.050e-01 2.069e+00 2.050e-01 6.980e-01\n",
      " 3.990e-01 6.060e-01 6.000e+00 3.000e+00 2.200e-02 3.050e+00]\n",
      " >>> Score     : -0.665 \n",
      "\n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 74.6847\n",
      "Function value obtained: -0.6655\n",
      "Current minimum: -0.6720\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "\n",
      "\n",
      " >>> Parameters: [9.800e-02 1.550e+02 6.000e+00 4.140e-01 2.030e+00 2.020e-01 7.010e-01\n",
      " 4.020e-01 6.020e-01 6.000e+00 3.000e+00 3.600e-02 3.081e+00]\n",
      " >>> Score     : -0.652 \n",
      "\n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 52.6868\n",
      "Function value obtained: -0.6522\n",
      "Current minimum: -0.6720\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "\n",
      "\n",
      " >>> Parameters: [9.400e-02 1.480e+02 6.000e+00 4.110e-01 2.069e+00 2.070e-01 7.020e-01\n",
      " 3.960e-01 6.030e-01 5.000e+00 3.000e+00 4.000e-02 3.022e+00]\n",
      " >>> Score     : -0.656 \n",
      "\n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 39.9531\n",
      "Function value obtained: -0.6555\n",
      "Current minimum: -0.6720\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "\n",
      "\n",
      " >>> Parameters: [9.300e-02 1.550e+02 6.000e+00 4.130e-01 1.994e+00 2.040e-01 7.050e-01\n",
      " 4.010e-01 6.070e-01 6.000e+00 3.000e+00 2.600e-02 2.987e+00]\n",
      " >>> Score     : -0.664 \n",
      "\n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 76.7508\n",
      "Function value obtained: -0.6637\n",
      "Current minimum: -0.6720\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "\n",
      "\n",
      " >>> Parameters: [9.600e-02 1.540e+02 6.000e+00 4.070e-01 2.012e+00 2.040e-01 6.980e-01\n",
      " 3.990e-01 6.000e-01 6.000e+00 4.000e+00 2.700e-02 3.029e+00]\n",
      " >>> Score     : -0.668 \n",
      "\n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 42.7591\n",
      "Function value obtained: -0.6682\n",
      "Current minimum: -0.6720\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "\n",
      "\n",
      " >>> Parameters: [9.500e-02 1.520e+02 6.000e+00 4.100e-01 2.061e+00 2.050e-01 7.010e-01\n",
      " 4.060e-01 5.990e-01 6.000e+00 3.000e+00 3.400e-02 3.011e+00]\n",
      " >>> Score     : -0.665 \n",
      "\n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 42.1782\n",
      "Function value obtained: -0.6645\n",
      "Current minimum: -0.6720\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "\n",
      "\n",
      " >>> Parameters: [9.100e-02 1.580e+02 6.000e+00 4.110e-01 2.025e+00 2.000e-01 7.000e-01\n",
      " 4.020e-01 6.030e-01 5.000e+00 4.000e+00 2.700e-02 3.024e+00]\n",
      " >>> Score     : -0.667 \n",
      "\n",
      "\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 42.5057\n",
      "Function value obtained: -0.6670\n",
      "Current minimum: -0.6720\n",
      "\n",
      "\n",
      " >>> Parameters: [9.200e-02 1.550e+02 5.000e+00 4.100e-01 1.996e+00 2.030e-01 7.060e-01\n",
      " 4.000e-01 6.020e-01 6.000e+00 4.000e+00 3.200e-02 3.080e+00]\n",
      " >>> Score     : -0.671 \n",
      "\n",
      "\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 80.3914\n",
      "Function value obtained: -0.6708\n",
      "Current minimum: -0.6720\n",
      "Best found params: [0.09295802371080336, 153.0, 5.0, 0.4089133795518697, 2.022077140566984, 0.20305923025452047, 0.7015475307175182, 0.4007270783935024, 0.603165785432596, 5.0, 3.0, 0.030907383711692726, 3.0361391192415588]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>colsample_bynode</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>num_parallel_tree</th>\n",
       "      <th>max_delta_step</th>\n",
       "      <th>min_correlation</th>\n",
       "      <th>z_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.092958</td>\n",
       "      <td>153.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.408913</td>\n",
       "      <td>2.022077</td>\n",
       "      <td>0.203059</td>\n",
       "      <td>0.701548</td>\n",
       "      <td>0.400727</td>\n",
       "      <td>0.603166</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030907</td>\n",
       "      <td>3.036139</td>\n",
       "      <td>-0.671960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.092438</td>\n",
       "      <td>155.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.409587</td>\n",
       "      <td>1.996065</td>\n",
       "      <td>0.203297</td>\n",
       "      <td>0.706317</td>\n",
       "      <td>0.399628</td>\n",
       "      <td>0.601637</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.032245</td>\n",
       "      <td>3.079813</td>\n",
       "      <td>-0.670838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.096309</td>\n",
       "      <td>154.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.406561</td>\n",
       "      <td>2.011859</td>\n",
       "      <td>0.203587</td>\n",
       "      <td>0.698197</td>\n",
       "      <td>0.399425</td>\n",
       "      <td>0.599630</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.026677</td>\n",
       "      <td>3.029468</td>\n",
       "      <td>-0.668169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.093756</td>\n",
       "      <td>156.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.412386</td>\n",
       "      <td>2.034434</td>\n",
       "      <td>0.201903</td>\n",
       "      <td>0.699523</td>\n",
       "      <td>0.396294</td>\n",
       "      <td>0.600892</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.030507</td>\n",
       "      <td>3.025418</td>\n",
       "      <td>-0.668078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.090975</td>\n",
       "      <td>158.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.410510</td>\n",
       "      <td>2.025398</td>\n",
       "      <td>0.200365</td>\n",
       "      <td>0.700496</td>\n",
       "      <td>0.401915</td>\n",
       "      <td>0.602914</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>3.024485</td>\n",
       "      <td>-0.667025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.092325</td>\n",
       "      <td>154.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.404906</td>\n",
       "      <td>2.069058</td>\n",
       "      <td>0.204591</td>\n",
       "      <td>0.698257</td>\n",
       "      <td>0.399309</td>\n",
       "      <td>0.605673</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.021676</td>\n",
       "      <td>3.049567</td>\n",
       "      <td>-0.665460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.095419</td>\n",
       "      <td>152.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.410303</td>\n",
       "      <td>2.061233</td>\n",
       "      <td>0.204860</td>\n",
       "      <td>0.701040</td>\n",
       "      <td>0.405513</td>\n",
       "      <td>0.599328</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.034416</td>\n",
       "      <td>3.011119</td>\n",
       "      <td>-0.664542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.092633</td>\n",
       "      <td>155.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.413096</td>\n",
       "      <td>1.993759</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>0.705199</td>\n",
       "      <td>0.400817</td>\n",
       "      <td>0.607333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.026462</td>\n",
       "      <td>2.987075</td>\n",
       "      <td>-0.663719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.093198</td>\n",
       "      <td>156.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.408649</td>\n",
       "      <td>1.990710</td>\n",
       "      <td>0.205428</td>\n",
       "      <td>0.698713</td>\n",
       "      <td>0.397079</td>\n",
       "      <td>0.601407</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.028637</td>\n",
       "      <td>3.076399</td>\n",
       "      <td>-0.662005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.096244</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.407596</td>\n",
       "      <td>2.067793</td>\n",
       "      <td>0.199463</td>\n",
       "      <td>0.705248</td>\n",
       "      <td>0.400463</td>\n",
       "      <td>0.606175</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.035320</td>\n",
       "      <td>3.044341</td>\n",
       "      <td>-0.661363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.094462</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.410650</td>\n",
       "      <td>2.069272</td>\n",
       "      <td>0.206841</td>\n",
       "      <td>0.701644</td>\n",
       "      <td>0.396284</td>\n",
       "      <td>0.602677</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.040499</td>\n",
       "      <td>3.022084</td>\n",
       "      <td>-0.655535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.097526</td>\n",
       "      <td>155.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.413866</td>\n",
       "      <td>2.030262</td>\n",
       "      <td>0.202203</td>\n",
       "      <td>0.701295</td>\n",
       "      <td>0.401962</td>\n",
       "      <td>0.601546</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.036474</td>\n",
       "      <td>3.081096</td>\n",
       "      <td>-0.652240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration  learning_rate  n_estimators  max_depth  subsample  \\\n",
       "0           0       0.092958         153.0        5.0   0.408913   \n",
       "11         11       0.092438         155.0        5.0   0.409587   \n",
       "8           8       0.096309         154.0        6.0   0.406561   \n",
       "1           1       0.093756         156.0        6.0   0.412386   \n",
       "10         10       0.090975         158.0        6.0   0.410510   \n",
       "4           4       0.092325         154.0        6.0   0.404906   \n",
       "9           9       0.095419         152.0        6.0   0.410303   \n",
       "7           7       0.092633         155.0        6.0   0.413096   \n",
       "3           3       0.093198         156.0        5.0   0.408649   \n",
       "2           2       0.096244         151.0        6.0   0.407596   \n",
       "6           6       0.094462         148.0        6.0   0.410650   \n",
       "5           5       0.097526         155.0        6.0   0.413866   \n",
       "\n",
       "    min_child_weight  reg_alpha  reg_lambda  colsample_bynode  \\\n",
       "0           2.022077   0.203059    0.701548          0.400727   \n",
       "11          1.996065   0.203297    0.706317          0.399628   \n",
       "8           2.011859   0.203587    0.698197          0.399425   \n",
       "1           2.034434   0.201903    0.699523          0.396294   \n",
       "10          2.025398   0.200365    0.700496          0.401915   \n",
       "4           2.069058   0.204591    0.698257          0.399309   \n",
       "9           2.061233   0.204860    0.701040          0.405513   \n",
       "7           1.993759   0.203711    0.705199          0.400817   \n",
       "3           1.990710   0.205428    0.698713          0.397079   \n",
       "2           2.067793   0.199463    0.705248          0.400463   \n",
       "6           2.069272   0.206841    0.701644          0.396284   \n",
       "5           2.030262   0.202203    0.701295          0.401962   \n",
       "\n",
       "    colsample_bytree  num_parallel_tree  max_delta_step  min_correlation  \\\n",
       "0           0.603166                5.0             3.0         0.030907   \n",
       "11          0.601637                6.0             4.0         0.032245   \n",
       "8           0.599630                6.0             4.0         0.026677   \n",
       "1           0.600892                5.0             4.0         0.030507   \n",
       "10          0.602914                5.0             4.0         0.026667   \n",
       "4           0.605673                6.0             3.0         0.021676   \n",
       "9           0.599328                6.0             3.0         0.034416   \n",
       "7           0.607333                6.0             3.0         0.026462   \n",
       "3           0.601407                5.0             3.0         0.028637   \n",
       "2           0.606175                6.0             4.0         0.035320   \n",
       "6           0.602677                5.0             3.0         0.040499   \n",
       "5           0.601546                6.0             3.0         0.036474   \n",
       "\n",
       "     z_score     score  \n",
       "0   3.036139 -0.671960  \n",
       "11  3.079813 -0.670838  \n",
       "8   3.029468 -0.668169  \n",
       "1   3.025418 -0.668078  \n",
       "10  3.024485 -0.667025  \n",
       "4   3.049567 -0.665460  \n",
       "9   3.011119 -0.664542  \n",
       "7   2.987075 -0.663719  \n",
       "3   3.076399 -0.662005  \n",
       "2   3.044341 -0.661363  \n",
       "6   3.022084 -0.655535  \n",
       "5   3.081096 -0.652240  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 20s, sys: 8.63 s, total: 30min 28s\n",
      "Wall time: 9min 22s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "N_CALLS = 11\n",
    "\n",
    "# res_gp = forest_minimize(\n",
    "#     train_function,\n",
    "#     space,\n",
    "#     base_estimator=\"RF\",\n",
    "#     random_state=0,\n",
    "#     verbose=1,\n",
    "#     n_calls=11,\n",
    "#     n_random_starts=10,\n",
    "#     n_jobs=n_jobs,\n",
    "# )\n",
    "\n",
    "\n",
    "results = pd.read_csv(\"../data/optimization_pipeline.csv\").sort_values(\"score\")\n",
    "x0 = list(results.drop([\"iteration\", \"score\"], 1).iloc[0].values)\n",
    "y0 = results[\"score\"].iloc[0]\n",
    "print(y0)\n",
    "par_0 = dict(zip(par_0.keys(), x0))\n",
    "\n",
    "\n",
    "res_gp = gp_minimize(\n",
    "    train_function,\n",
    "    space,\n",
    "    x0=x0,\n",
    "    y0=y0,\n",
    "    random_state=0,\n",
    "    verbose=1,\n",
    "    n_calls=N_CALLS,\n",
    "    n_random_starts=10,\n",
    "    n_jobs=n_jobs,\n",
    ")\n",
    "\n",
    "# res_gp = forest_minimize(\n",
    "#     train_function,\n",
    "#     space,\n",
    "#     x0=x0,\n",
    "#     y0=y0,\n",
    "#     base_estimator=\"RF\",\n",
    "#     random_state=0,\n",
    "#     verbose=1,\n",
    "#     n_calls=N_CALLS,\n",
    "#     n_random_starts=10,\n",
    "#     n_jobs=n_jobs,\n",
    "# )\n",
    "\n",
    "xgb_best_params = res_gp.x\n",
    "\n",
    "print(f\"Best found params: {xgb_best_params}\")\n",
    "\n",
    "plot_convergence(res_gp)\n",
    "\n",
    "results = (\n",
    "    pd.DataFrame(res_gp.x_iters, columns=PARAMETER_NAMES)\n",
    "    .assign(score=res_gp.func_vals)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"iteration\"})\n",
    "    .sort_values(\"score\")\n",
    ")\n",
    "\n",
    "# results.to_csv(\"../data/optimization_pipeline.csv\", index=False, mode='a',header=False)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15a33c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../data/optimization_pipeline.csv\", index=False, mode='a',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26074a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results.to_csv(\"../data/optimization_pipeline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "714ba24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def func(parameters):\n",
    "    learning_rate = parameters[\"learning_rate\"]\n",
    "    max_depth = parameters[\"max_depth\"]\n",
    "    min_correlation = parameters[2]\n",
    "\n",
    "    estimator = XGBClassifier(n_jobs=n_jobs, random_state=42, eval_metric=\"logloss\")\n",
    "\n",
    "    min_correlation = min_correlation\n",
    "    z_score_range = (-3,3)\n",
    "    polynomial_degree = 1\n",
    "\n",
    "\n",
    "    model = Model(\n",
    "        estimator,\n",
    "        classifier_params=params,\n",
    "        min_correlation=min_correlation,\n",
    "        z_score_range=z_score_range,\n",
    "        polynomial_degree = polynomial_degree,\n",
    "    )\n",
    "\n",
    "    # model.fit(X, y)\n",
    "\n",
    "    return model.cross_validate_score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "15b4568c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.670192813380508"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func([0.091,4,0.02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b1f215aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var8</th>\n",
       "      <th>var4</th>\n",
       "      <th>var8*var8</th>\n",
       "      <th>var8*var4</th>\n",
       "      <th>var4*var4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750154</td>\n",
       "      <td>5.627312e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.102039</td>\n",
       "      <td>0.075342</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.007688</td>\n",
       "      <td>5.676485e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>9.931948e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.070647</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>3.609462e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749085</td>\n",
       "      <td>5.611277e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35295</th>\n",
       "      <td>0.127389</td>\n",
       "      <td>0.699662</td>\n",
       "      <td>0.016228</td>\n",
       "      <td>0.089129</td>\n",
       "      <td>4.895268e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35296</th>\n",
       "      <td>0.137098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35301</th>\n",
       "      <td>0.137098</td>\n",
       "      <td>0.394328</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.054062</td>\n",
       "      <td>1.554949e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35304</th>\n",
       "      <td>0.137098</td>\n",
       "      <td>0.221102</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.030313</td>\n",
       "      <td>4.888594e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35306</th>\n",
       "      <td>0.130689</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.017080</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>8.483637e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14123 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           var8      var4  var8*var8  var8*var4     var4*var4\n",
       "id                                                           \n",
       "1      1.000000  0.750154   1.000000   0.750154  5.627312e-01\n",
       "8      0.102039  0.075342   0.010412   0.007688  5.676485e-03\n",
       "30     1.000000  0.031515   1.000000   0.031515  9.931948e-04\n",
       "43     0.070647  0.000601   0.004991   0.000042  3.609462e-07\n",
       "46     1.000000  0.749085   1.000000   0.749085  5.611277e-01\n",
       "...         ...       ...        ...        ...           ...\n",
       "35295  0.127389  0.699662   0.016228   0.089129  4.895268e-01\n",
       "35296  0.137098  0.000000   0.018796   0.000000  0.000000e+00\n",
       "35301  0.137098  0.394328   0.018796   0.054062  1.554949e-01\n",
       "35304  0.137098  0.221102   0.018796   0.030313  4.888594e-02\n",
       "35306  0.130689  0.002913   0.017080   0.000381  8.483637e-06\n",
       "\n",
       "[14123 rows x 5 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(X,y) # x+y+z+x**2+x*y+x*z+ y**2 + y*z + z**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa77df0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.03151499, 0.92269694])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(X,y)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eceeb9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0290787848371306"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.03151499 * 0.92269694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59254fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0104119697656836"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y + x**2 + x*y + y**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44c533c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var8', 'var4'], dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b685f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005676484772002501"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.07534245**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b11993d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.75015412],\n",
       "       [0.10203906, 0.07534245],\n",
       "       [1.        , 0.03151499],\n",
       "       ...,\n",
       "       [0.13709798, 0.39432838],\n",
       "       [0.13709798, 0.22110165],\n",
       "       [0.13068922, 0.00291267]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79247ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 + y2 + x + y + xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "97529223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var8</th>\n",
       "      <th>var4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-999</td>\n",
       "      <td>29442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>13684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-999</td>\n",
       "      <td>10232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10</td>\n",
       "      <td>2689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-999</td>\n",
       "      <td>29428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35295</th>\n",
       "      <td>24</td>\n",
       "      <td>28766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35296</th>\n",
       "      <td>27</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35301</th>\n",
       "      <td>27</td>\n",
       "      <td>23761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35304</th>\n",
       "      <td>27</td>\n",
       "      <td>19593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35306</th>\n",
       "      <td>25</td>\n",
       "      <td>4612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var8   var4\n",
       "id                \n",
       "1      -999  29442\n",
       "8        17  13684\n",
       "30     -999  10232\n",
       "43       10   2689\n",
       "46     -999  29428\n",
       "...     ...    ...\n",
       "35295    24  28766\n",
       "35296    27   -999\n",
       "35301    27  23761\n",
       "35304    27  19593\n",
       "35306    25   4612\n",
       "\n",
       "[14123 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02ee4c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ZClipper', ZClipper())])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_correlation = 0.1\n",
    "\n",
    "model.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5475bdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:23:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:23:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:23:21] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:23:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:23:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:23:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.6657156504798813"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimator = XGBClassifier(\n",
    "#     n_jobs=n_jobs,\n",
    "#     random_state=42,\n",
    "    \n",
    "# )\n",
    "\n",
    "# model = Model(estimator,classifier_params={\"learning_rate\": 0.2, \"max_depth\": 3})\n",
    "\n",
    "# model.fit(train.drop(\"y\", 1), train[\"y\"])\n",
    "\n",
    "# model.cross_validate_score(train.drop(\"y\", 1), train[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3bd147e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b5905166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=14123, step=1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8e2e3663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,     3,     4, ..., 14102, 14114, 14120])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a6047e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fold_index in range(5):\n",
    "fold_index = 0\n",
    "if True:\n",
    "    train_index, validation_index = stratified_folds[fold_index]\n",
    "    #temp.loc[train[temp.index.isin(validation_index)].index, \"fold\"] = fold_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d2d3f798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   30,    43,    46,    69,   149,   160,   242,   244,   286,\n",
       "              298,\n",
       "            ...\n",
       "            35115, 35125, 35127, 35151, 35156, 35159, 35228, 35236, 35279,\n",
       "            35301],\n",
       "           dtype='int64', name='id', length=2825)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[temp.index.isin(validation_index)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20656ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     5, ..., 14119, 14121, 14122]),\n",
       " array([    2,     3,     4, ..., 14102, 14114, 14120]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratified_folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "235241d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate_score(train.drop(\"y\",1),train[\"y\"],estimator=model.classifier,n_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab32c6a",
   "metadata": {
    "papermill": {
     "duration": 0.021714,
     "end_time": "2021-08-29T15:20:07.279350",
     "exception": false,
     "start_time": "2021-08-29T15:20:07.257636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGBoost - Tree Based Optimisation + LR Decay  \n",
    "#### In this notebook I won't get in to the details of the dataset(dealing with missing data, preprocessing and so on), since my objective here is to share a hyper parameter tuning technique and to demonstrate on how to apply learning rate decay on XGBoost training.  \n",
    "#### If it does help you in any way, please upvote!  \n",
    "Feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/gabriel-tardochi-salles-a1653a193/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c531ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T15:20:07.316510Z",
     "iopub.status.busy": "2021-08-29T15:20:07.315316Z",
     "iopub.status.idle": "2021-08-29T15:20:08.790802Z",
     "shell.execute_reply": "2021-08-29T15:20:08.790105Z",
     "shell.execute_reply.started": "2021-08-29T15:18:33.906883Z"
    },
    "papermill": {
     "duration": 1.49323,
     "end_time": "2021-08-29T15:20:08.791003",
     "exception": false,
     "start_time": "2021-08-29T15:20:07.297773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "from skopt import forest_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49c16cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3779b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "n_jobs = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054d664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1f88318",
   "metadata": {
    "papermill": {
     "duration": 0.01334,
     "end_time": "2021-08-29T15:20:08.818208",
     "exception": false,
     "start_time": "2021-08-29T15:20:08.804868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reading data from Porto Seguro Data Challenge 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85c5f843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T15:20:08.852646Z",
     "iopub.status.busy": "2021-08-29T15:20:08.851923Z",
     "iopub.status.idle": "2021-08-29T15:20:09.305526Z",
     "shell.execute_reply": "2021-08-29T15:20:09.304963Z",
     "shell.execute_reply.started": "2021-08-29T15:18:33.915628Z"
    },
    "papermill": {
     "duration": 0.473368,
     "end_time": "2021-08-29T15:20:09.305661",
     "exception": false,
     "start_time": "2021-08-29T15:20:08.832293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4644c55e635a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minp_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'metadata.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shuffling dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/metadata.csv'"
     ]
    }
   ],
   "source": [
    "inp_path = 'data/'\n",
    "metadata = pd.read_csv(inp_path + 'metadata.csv')\n",
    "test = pd.read_csv(inp_path + 'test.csv')\n",
    "train = pd.read_csv(inp_path + 'train.csv')\n",
    "train = train.sample(frac=1, random_state=0).reset_index(drop=True)  # shuffling dataset\n",
    "sub = pd.read_csv(inp_path + 'submission_sample.csv')\n",
    "\n",
    "\n",
    "\n",
    "# train = pd.read_csv('train_1.csv')\n",
    "# train_2 = pd.read_csv('train_2.csv')\n",
    "# test = pd.read_csv('test_1.csv')\n",
    "# test_2 = pd.read_csv('test_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3f94d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>var10</th>\n",
       "      <th>var11</th>\n",
       "      <th>var12</th>\n",
       "      <th>var13</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>var17</th>\n",
       "      <th>var18</th>\n",
       "      <th>var19</th>\n",
       "      <th>var20</th>\n",
       "      <th>var21</th>\n",
       "      <th>var22</th>\n",
       "      <th>var23</th>\n",
       "      <th>var24</th>\n",
       "      <th>var25</th>\n",
       "      <th>var26</th>\n",
       "      <th>var27</th>\n",
       "      <th>var28</th>\n",
       "      <th>var29</th>\n",
       "      <th>var30</th>\n",
       "      <th>var31</th>\n",
       "      <th>var32</th>\n",
       "      <th>var33</th>\n",
       "      <th>var34</th>\n",
       "      <th>var35</th>\n",
       "      <th>var36</th>\n",
       "      <th>var37</th>\n",
       "      <th>var38</th>\n",
       "      <th>var39</th>\n",
       "      <th>var40</th>\n",
       "      <th>var41</th>\n",
       "      <th>var42</th>\n",
       "      <th>var43</th>\n",
       "      <th>var44</th>\n",
       "      <th>var45</th>\n",
       "      <th>var46</th>\n",
       "      <th>var47</th>\n",
       "      <th>var48</th>\n",
       "      <th>var49</th>\n",
       "      <th>var50</th>\n",
       "      <th>var51</th>\n",
       "      <th>var52</th>\n",
       "      <th>var53</th>\n",
       "      <th>var54</th>\n",
       "      <th>var55</th>\n",
       "      <th>var56</th>\n",
       "      <th>var57</th>\n",
       "      <th>var58</th>\n",
       "      <th>var59</th>\n",
       "      <th>var60</th>\n",
       "      <th>var61</th>\n",
       "      <th>var62</th>\n",
       "      <th>var63</th>\n",
       "      <th>var64</th>\n",
       "      <th>var65</th>\n",
       "      <th>var66</th>\n",
       "      <th>var67</th>\n",
       "      <th>var68</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>1353</td>\n",
       "      <td>28956</td>\n",
       "      <td>743</td>\n",
       "      <td>1289</td>\n",
       "      <td>27</td>\n",
       "      <td>-999</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4530</td>\n",
       "      <td>914</td>\n",
       "      <td>991</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1155</td>\n",
       "      <td>19</td>\n",
       "      <td>1031</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>413</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217528</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.367742</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.201839</td>\n",
       "      <td>0.353965</td>\n",
       "      <td>0.166641</td>\n",
       "      <td>0.049108</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.016683</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.253676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>1446</td>\n",
       "      <td>7803</td>\n",
       "      <td>5151</td>\n",
       "      <td>935</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>8731</td>\n",
       "      <td>1341</td>\n",
       "      <td>2033</td>\n",
       "      <td>26</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>1299</td>\n",
       "      <td>26</td>\n",
       "      <td>773</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>692</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221968</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.177047</td>\n",
       "      <td>0.072127</td>\n",
       "      <td>0.074555</td>\n",
       "      <td>0.217009</td>\n",
       "      <td>0.144403</td>\n",
       "      <td>0.892028</td>\n",
       "      <td>0.038323</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.099265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>243</td>\n",
       "      <td>4325</td>\n",
       "      <td>1109</td>\n",
       "      <td>1903</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>10131</td>\n",
       "      <td>914</td>\n",
       "      <td>1503</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>1294</td>\n",
       "      <td>24</td>\n",
       "      <td>1562</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>553</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.213224</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.101075</td>\n",
       "      <td>0.210879</td>\n",
       "      <td>0.324770</td>\n",
       "      <td>0.384992</td>\n",
       "      <td>0.330680</td>\n",
       "      <td>0.072864</td>\n",
       "      <td>0.930373</td>\n",
       "      <td>0.021052</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.136029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>419</td>\n",
       "      <td>743</td>\n",
       "      <td>7750</td>\n",
       "      <td>183</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>636</td>\n",
       "      <td>5879</td>\n",
       "      <td>146</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>811</td>\n",
       "      <td>26</td>\n",
       "      <td>152</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>662</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.205044</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.131070</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.244936</td>\n",
       "      <td>0.158088</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.220588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>1863</td>\n",
       "      <td>22693</td>\n",
       "      <td>5625</td>\n",
       "      <td>965</td>\n",
       "      <td>9</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>24967</td>\n",
       "      <td>4427</td>\n",
       "      <td>772</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.024989</td>\n",
       "      <td>0.225166</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>0.252794</td>\n",
       "      <td>0.080405</td>\n",
       "      <td>0.944501</td>\n",
       "      <td>0.021806</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.113971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21178</th>\n",
       "      <td>35297</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>1460</td>\n",
       "      <td>13335</td>\n",
       "      <td>9048</td>\n",
       "      <td>620</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>13567</td>\n",
       "      <td>2617</td>\n",
       "      <td>572</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1573</td>\n",
       "      <td>26</td>\n",
       "      <td>592</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>332</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.213106</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.387701</td>\n",
       "      <td>0.148933</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.326307</td>\n",
       "      <td>0.132833</td>\n",
       "      <td>0.968718</td>\n",
       "      <td>0.039626</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.253676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21179</th>\n",
       "      <td>35298</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>532</td>\n",
       "      <td>14837</td>\n",
       "      <td>2590</td>\n",
       "      <td>855</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>15367</td>\n",
       "      <td>2261</td>\n",
       "      <td>678</td>\n",
       "      <td>19</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>1383</td>\n",
       "      <td>19</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>578</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.210435</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.101075</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.179243</td>\n",
       "      <td>0.205030</td>\n",
       "      <td>0.229354</td>\n",
       "      <td>0.052108</td>\n",
       "      <td>0.940464</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.209559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21180</th>\n",
       "      <td>35300</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>2923</td>\n",
       "      <td>16685</td>\n",
       "      <td>3162</td>\n",
       "      <td>1604</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>17658</td>\n",
       "      <td>4369</td>\n",
       "      <td>1279</td>\n",
       "      <td>26</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>971</td>\n",
       "      <td>26</td>\n",
       "      <td>1334</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>74</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.218353</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.367742</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.237607</td>\n",
       "      <td>0.810448</td>\n",
       "      <td>0.179781</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>0.745711</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.161765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21181</th>\n",
       "      <td>35302</td>\n",
       "      <td>5</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>367</td>\n",
       "      <td>7637</td>\n",
       "      <td>1389</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>28370</td>\n",
       "      <td>679</td>\n",
       "      <td>1117</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>868</td>\n",
       "      <td>26</td>\n",
       "      <td>1158</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.224865</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.246237</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.102662</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.149598</td>\n",
       "      <td>0.032583</td>\n",
       "      <td>0.891019</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.246324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21182</th>\n",
       "      <td>35303</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>1446</td>\n",
       "      <td>6031</td>\n",
       "      <td>853</td>\n",
       "      <td>829</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3182</td>\n",
       "      <td>5360</td>\n",
       "      <td>1910</td>\n",
       "      <td>26</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1473</td>\n",
       "      <td>26</td>\n",
       "      <td>675</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>89</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.207270</td>\n",
       "      <td>0.031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020069</td>\n",
       "      <td>0.313769</td>\n",
       "      <td>0.092545</td>\n",
       "      <td>0.285876</td>\n",
       "      <td>0.079940</td>\n",
       "      <td>0.901110</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21183 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  var1  var2  var3   var4  var5  var6  var7  var8  var9  var10  \\\n",
       "0          0     5   126  1353  28956   743  1289    27  -999     1     33   \n",
       "1          2     6   126  1446   7803  5151   935    35  -999     3     63   \n",
       "2          4     5    44   243   4325  1109  1903    33    24     1     63   \n",
       "3          7     4    53   419    743  7750   183    35  -999     3     14   \n",
       "4         15     4   126  1863  22693  5625   965     9  -999     3     63   \n",
       "...      ...   ...   ...   ...    ...   ...   ...   ...   ...   ...    ...   \n",
       "21178  35297     4   126  1460  13335  9048   620    35    27     3     63   \n",
       "21179  35298    18    19   532  14837  2590   855    27    20     3     63   \n",
       "21180  35300     4   126  2923  16685  3162  1604    35  -999     3     63   \n",
       "21181  35302     5  -999  -999    367  7637  1389    35  -999     3     63   \n",
       "21182  35303     6   126  1446   6031   853   829    35    27     3     14   \n",
       "\n",
       "       var11  var12  var13  var14  var15  var16  var17  var18  var19  var20  \\\n",
       "0       4530    914    991     19      1      3      3      3   1155     19   \n",
       "1       8731   1341   2033     26     58     58     22      5   1299     26   \n",
       "2      10131    914   1503     24     60     61     23      5   1294     24   \n",
       "3        636   5879    146     26     22     22     10      4    811     26   \n",
       "4      24967   4427    772      5     73     73     29      5    595      5   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "21178  13567   2617    572     26     37     35     11      4   1573     26   \n",
       "21179  15367   2261    678     19   -999   -999   -999   -999   1383     19   \n",
       "21180  17658   4369   1279     26   -999   -999   -999   -999    971     26   \n",
       "21181  28370    679   1117     26     34     34     10      4    868     26   \n",
       "21182   3182   5360   1910     26     55     56     20      5   1473     26   \n",
       "\n",
       "       var21  var22  var23  var24  var25  var26  var27  var28  var29  var30  \\\n",
       "0       1031      5      3      2      3      7      0     25      4      1   \n",
       "1        773      5      3      1      2      1      0     25      4      0   \n",
       "2       1562      5      4      1      0      1      0     26      5      2   \n",
       "3        152      5      3      2      4      4      0     24      4      2   \n",
       "4        796      0      1      0      1      7      0     11      2      1   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "21178    592      5      3      2      1      1      0     24      4      1   \n",
       "21179    700      0      3      2      1   -999      0     25      4      1   \n",
       "21180   1334      5      3      0      1   -999      0     24      4      1   \n",
       "21181   1158      5      3      2      1      9      0     24      4      1   \n",
       "21182    675      5      3      2      1      7      1     24      4      1   \n",
       "\n",
       "       var31  var32  var33  var34  var35  var36  var37  var38  var39  var40  \\\n",
       "0          0     11      2     62    413     27      0      0      4      6   \n",
       "1          1      6      5     58    692     21     15      8      4      0   \n",
       "2          0     17      0     12    553      0     18      0      4     10   \n",
       "3          0     12      5     38    662     28      1      0      4      9   \n",
       "4          0     21      3     18    546      0      1      0      4      6   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "21178      0     21      6     42    332     21     20      9      1     11   \n",
       "21179      0     20      0     60    578      2      0      0      4      2   \n",
       "21180      0     12      5     49     74     28      2      0      4      4   \n",
       "21181      0     15      5     54    434      0      1      0      4     19   \n",
       "21182      0     15      6     33     89     31      4      0      4     16   \n",
       "\n",
       "       var41  var42  var43  var44  var45  var46  var47  var48  var49  var50  \\\n",
       "0          3     24      3      1      0      0      0      0      0      0   \n",
       "1          1     30      0      1      0      0      0      0      0      0   \n",
       "2          3     26     14      1      0      0      0      0      0      0   \n",
       "3          3     28      7      1      0      0      0      0      0      1   \n",
       "4          3     28      8      1      0      0      0      0      1      0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "21178      3     25     13      1      0      0      0      0      0      0   \n",
       "21179      3     26      6      1      0      0      0      0      0      0   \n",
       "21180      3     19      4      1      0      0      0      0      0      0   \n",
       "21181      3     23      6      1      0      0      0      0      0      0   \n",
       "21182      3     22     11      1      0      0      0      0      0      0   \n",
       "\n",
       "       var51  var52  var53  var54     var55  var56     var57       var58  \\\n",
       "0          0     44      1      1  0.217528  0.272  0.367742    0.062900   \n",
       "1          0     13      1      1  0.221968  0.853  0.053763    0.177047   \n",
       "2          0     36      1      1  0.213224  0.632  0.101075    0.210879   \n",
       "3          0     13      1      1  0.205044  0.117  0.935484    0.007068   \n",
       "4          0     51      1      1  0.203750  0.079  0.967742    0.024989   \n",
       "...      ...    ...    ...    ...       ...    ...       ...         ...   \n",
       "21178      0     34      2      2  0.213106  0.065  0.967742    0.387701   \n",
       "21179      0     10      2      2  0.210435  0.740  0.101075 -999.000000   \n",
       "21180      0     39      2      2  0.218353  0.288  0.367742 -999.000000   \n",
       "21181      0      3      2      2  0.224865  0.324  0.246237    0.199008   \n",
       "21182      0     19      2      2  0.207270  0.031  1.000000    0.020069   \n",
       "\n",
       "          var59       var60     var61     var62     var63     var64  var65  \\\n",
       "0      0.201839    0.353965  0.166641  0.049108  0.986882  0.016683 -999.0   \n",
       "1      0.072127    0.074555  0.217009  0.144403  0.892028  0.038323 -999.0   \n",
       "2      0.324770    0.384992  0.330680  0.072864  0.930373  0.021052 -999.0   \n",
       "3      0.131070 -999.000000  0.244936  0.158088  0.986882  0.022649 -999.0   \n",
       "4      0.225166    0.059940  0.252794  0.080405  0.944501  0.021806 -999.0   \n",
       "...         ...         ...       ...       ...       ...       ...    ...   \n",
       "21178  0.148933 -999.000000  0.326307  0.132833  0.968718  0.039626 -999.0   \n",
       "21179  0.179243    0.205030  0.229354  0.052108  0.940464  0.016952 -999.0   \n",
       "21180  0.237607    0.810448  0.179781  0.029155  0.745711  0.020158 -999.0   \n",
       "21181  0.102662 -999.000000  0.149598  0.032583  0.891019  0.012596 -999.0   \n",
       "21182  0.313769    0.092545  0.285876  0.079940  0.901110  0.026239 -999.0   \n",
       "\n",
       "       var66       var67     var68  \n",
       "0     -999.0    0.176471  0.253676  \n",
       "1     -999.0    0.147059  0.099265  \n",
       "2     -999.0    0.294118  0.136029  \n",
       "3     -999.0    0.294118  0.220588  \n",
       "4     -999.0    0.352941  0.113971  \n",
       "...      ...         ...       ...  \n",
       "21178 -999.0    0.323529  0.253676  \n",
       "21179 -999.0    0.088235  0.209559  \n",
       "21180 -999.0    0.205882  0.161765  \n",
       "21181 -999.0 -999.000000  0.246324  \n",
       "21182 -999.0    0.191176  0.312500  \n",
       "\n",
       "[21183 rows x 69 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6f507",
   "metadata": {
    "papermill": {
     "duration": 0.013412,
     "end_time": "2021-08-29T15:20:09.332930",
     "exception": false,
     "start_time": "2021-08-29T15:20:09.319518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building Cross Validation (Stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5739aae4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T15:20:09.375537Z",
     "iopub.status.busy": "2021-08-29T15:20:09.374756Z",
     "iopub.status.idle": "2021-08-29T15:20:09.399941Z",
     "shell.execute_reply": "2021-08-29T15:20:09.400552Z",
     "shell.execute_reply.started": "2021-08-29T15:18:34.230504Z"
    },
    "papermill": {
     "duration": 0.054198,
     "end_time": "2021-08-29T15:20:09.400735",
     "exception": false,
     "start_time": "2021-08-29T15:20:09.346537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def _gen_strat_folds(df, tgt_name, n_splits=5, shuffle=True, random_state=0):\n",
    "#     \"\"\" Creates Folds Inplace \"\"\"\n",
    "#     skf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "#     for fold, (train_index, valid_index) in enumerate(skf.split(df.drop(columns=tgt_name), df[tgt_name])):\n",
    "#         df.loc[df[df.index.isin(valid_index)].index, 'fold'] = fold\n",
    "\n",
    "# _gen_strat_folds(train, 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee4710",
   "metadata": {
    "papermill": {
     "duration": 0.013661,
     "end_time": "2021-08-29T15:20:09.428571",
     "exception": false,
     "start_time": "2021-08-29T15:20:09.414910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### XGBoost Classifier Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7133bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stratified_folds(train, n_folds=5, shuffle=True, random_state=42):\n",
    "\n",
    "    temp = train.copy()\n",
    "\n",
    "    # Instaciando o estritificador\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    # Gerando os index com os folds\n",
    "    stratified_folds = list(skf.split(X=temp.drop(columns=\"y\"), y=temp[\"y\"]))\n",
    "\n",
    "    for fold_index in range(n_folds):\n",
    "\n",
    "        train_index, validation_index = stratified_folds[fold_index]\n",
    "\n",
    "        temp.loc[train[temp.index.isin(validation_index)].index, \"fold\"] = fold_index\n",
    "\n",
    "    return temp[\"fold\"].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc3c4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.base import TransformerMixin, BaseEstimator\n",
    "# from copy import deepcopy\n",
    "\n",
    "\n",
    "# def dataframe_transform(data, transformer):\n",
    "#     return pd.DataFrame(\n",
    "#         transformer.transform(data), columns=data.columns, index=data.index\n",
    "#     )\n",
    "\n",
    "\n",
    "# class Model(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, classifier):\n",
    "#         self.classifier = classifier\n",
    "\n",
    "#     def fit(self, X, y=None, **fit_params):\n",
    "\n",
    "#         self.classifier.fit(X, y, **fit_params)\n",
    "\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "#         return X\n",
    "\n",
    "#     def predict(self, X, threshold=0.5):\n",
    "#         predict_prob = self.classifier.predict_proba(X)[:, 1]\n",
    "#         condition = lambda x: x > threshold\n",
    "#         vec_condition = np.vectorize(condition)\n",
    "#         return np.where(vec_condition(predict_prob), 1, 0)\n",
    "\n",
    "#     def predict_proba(self, X):\n",
    "#         return self.classifier.predict_proba(X)[:, 1]\n",
    "\n",
    "#     def cross_validate_score(\n",
    "#         self, X, y, n_folds=5, threshold=0.3, random_state=42, verbose=0, fit_params={}\n",
    "#     ):\n",
    "#         return cross_validate_score(\n",
    "#             X=X,\n",
    "#             y=y,\n",
    "#             estimator = self.classifier,\n",
    "#             n_folds=n_folds,\n",
    "#             scoring=f1_score,\n",
    "#             threshold=0.3,\n",
    "#             random_state=42,\n",
    "#             verbose=0,\n",
    "#             fit_params = {}\n",
    "#         )\n",
    "\n",
    "\n",
    "# estimator = XGBClassifier(n_jobs=n_jobs, random_state=42)\n",
    "\n",
    "# model = Model(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5083166",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a17a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_score(\n",
    "    X,\n",
    "    y,\n",
    "    estimator,\n",
    "    n_folds=5,\n",
    "    scoring=f1_score,\n",
    "    threshold=0.3,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    fit_params = {}\n",
    "):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # estimator = XGBClassifier(\n",
    "    #    n_jobs=n_jobs,\n",
    "    #    random_state=random_state,\n",
    "    # )\n",
    "\n",
    "    temp = X.assign(y=y)\n",
    "\n",
    "    temp[\"fold\"] = generate_stratified_folds(temp, n_folds=n_folds)\n",
    "\n",
    "    iterator = (\n",
    "        range(n_folds) if verbose < 1 else tqdm(range(n_folds), desc=\"Cross validation\")\n",
    "    )\n",
    "\n",
    "    for fold in iterator:\n",
    "\n",
    "        # Separando os dados de treinamento para essa fold\n",
    "        train_data = temp[temp[\"fold\"] != fold].copy()\n",
    "\n",
    "        # Separando os dados de teste para esse fold\n",
    "        test_data = temp[temp[\"fold\"] == fold].copy()\n",
    "\n",
    "        X_train = train_data.drop(columns=[\"fold\", \"y\"]).values\n",
    "\n",
    "        X_test = test_data.drop(columns=[\"fold\", \"y\"]).values\n",
    "\n",
    "        y_train = train_data[\"y\"].values\n",
    "\n",
    "        y_test = test_data[\"y\"].values\n",
    "        \n",
    "        fit_params[\"eval_set\"] = [(X_test, y_test)]\n",
    "\n",
    "        estimator.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "        prob_test = estimator.predict_proba(X_test)[:, -1]\n",
    "\n",
    "        scores.append(scoring(y_test, prob_test > threshold))\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "    \n",
    "    return -avg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374ae92f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T15:20:09.459530Z",
     "iopub.status.busy": "2021-08-29T15:20:09.458862Z",
     "iopub.status.idle": "2021-08-29T15:20:24.149943Z",
     "shell.execute_reply": "2021-08-29T15:20:24.150499Z",
     "shell.execute_reply.started": "2021-08-29T15:18:34.261947Z"
    },
    "papermill": {
     "duration": 14.708256,
     "end_time": "2021-08-29T15:20:24.150690",
     "exception": false,
     "start_time": "2021-08-29T15:20:09.442434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scores = []\n",
    "# xgb = XGBClassifier(\n",
    "#     n_jobs=n_jobs,\n",
    "#     random_state=42,\n",
    "# )\n",
    "\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score,f1_score\n",
    "\n",
    "# threshold = 0.3\n",
    "\n",
    "# def custom_f1_score(prob, dtrain):\n",
    "    \n",
    "#     labels = dtrain.get_label()\n",
    "    \n",
    "#     preds = prob > threshold\n",
    "#     f1 = f1_score(labels, preds)\n",
    "    \n",
    "#     return (\"f1_score\", f1)\n",
    "\n",
    "# for fold in tqdm(range(5), desc=\"Cross validation progress\"):\n",
    "\n",
    "#     # Separando os dados de treinamento para essa fold\n",
    "#     train_data = train[train.fold != fold].copy()\n",
    "\n",
    "#     # Separando os dados de teste para esse fold\n",
    "#     test_data = train[train.fold == fold].copy()\n",
    "\n",
    "#     X_train = train_data.drop(columns=[\"fold\", \"y\"]).values\n",
    "\n",
    "#     X_test = test_data.drop(columns=[\"fold\", \"y\"]).values\n",
    "\n",
    "#     y_train = train_data[\"y\"].values\n",
    "\n",
    "#     y_test = test_data[\"y\"].values\n",
    "\n",
    "#     fit_params = {\n",
    "#         \"early_stopping_rounds\": 100,\n",
    "#         'eval_metric' : custom_f1_score,\n",
    "#         \"eval_set\": [(X_test, y_test)],\n",
    "#     }\n",
    "\n",
    "#     xgb.fit(X_train, y_train, verbose=0, **fit_params)\n",
    "    \n",
    "# #     p = xgb.predict_proba(X_test)[:, -1]\n",
    "    \n",
    "# #     scores.append(f1_score(y_test, p > threshold))\n",
    "\n",
    "# # avg_score = np.mean(scores)\n",
    "# # print(f\"Baseline auc = {round(avg_score, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00ba64",
   "metadata": {
    "papermill": {
     "duration": 0.014224,
     "end_time": "2021-08-29T15:20:24.180239",
     "exception": false,
     "start_time": "2021-08-29T15:20:24.166015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tree Based Optimisation (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f885e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "fit_params = {\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"eval_metric\": \"auc\",\n",
    "}\n",
    "\n",
    "# random_state = 42\n",
    "# threshold = 0.3\n",
    "# n_folds = 5\n",
    "# threshold = 0.3\n",
    "# verbose = 0\n",
    "\n",
    "def cross_validate_score(\n",
    "    X,\n",
    "    y,\n",
    "    estimator,\n",
    "    n_folds=5,\n",
    "    scoring=f1_score,\n",
    "    threshold=0.3,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    fit_params = {}\n",
    "):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # estimator = XGBClassifier(\n",
    "    #    n_jobs=n_jobs,\n",
    "    #    random_state=random_state,\n",
    "    # )\n",
    "\n",
    "    temp = X.assign(y=y)\n",
    "\n",
    "    temp[\"fold\"] = generate_stratified_folds(temp, n_folds=n_folds)\n",
    "\n",
    "    iterator = (\n",
    "        range(n_folds) if verbose < 1 else tqdm(range(n_folds), desc=\"Cross validation\")\n",
    "    )\n",
    "\n",
    "    for fold in iterator:\n",
    "\n",
    "        # Separando os dados de treinamento para essa fold\n",
    "        train_data = temp[temp[\"fold\"] != fold].copy()\n",
    "\n",
    "        # Separando os dados de teste para esse fold\n",
    "        test_data = temp[temp[\"fold\"] == fold].copy()\n",
    "\n",
    "        X_train = train_data.drop(columns=[\"fold\", \"y\"]).values\n",
    "\n",
    "        X_test = test_data.drop(columns=[\"fold\", \"y\"]).values\n",
    "\n",
    "        y_train = train_data[\"y\"].values\n",
    "\n",
    "        y_test = test_data[\"y\"].values\n",
    "        \n",
    "        fit_params[\"eval_set\"] = [(X_test, y_test)]\n",
    "\n",
    "        estimator.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "        prob_test = estimator.predict_proba(X_test)[:, -1]\n",
    "\n",
    "        scores.append(scoring(y_test, prob_test > threshold))\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "    \n",
    "    return -avg_score\n",
    "\n",
    "\n",
    "# estimator = XGBClassifier(\n",
    "#     n_jobs=n_jobs,\n",
    "#     random_state=42,\n",
    "#     **dict(zip(parameter_names,[0.5,3,3,0.1,0.5,2]))\n",
    "# )\n",
    "\n",
    "# fit_params = {\n",
    "#     \"early_stopping_rounds\": 100,\n",
    "#     \"eval_metric\": \"auc\",\n",
    "#     \"verbose\": 0,\n",
    "# }\n",
    "\n",
    "# avg_score = cross_validate_score(\n",
    "#     X = train.drop(\"y\",1),\n",
    "#     y = train[\"y\"],\n",
    "#     estimator = estimator,\n",
    "#     fit_params = fit_params,\n",
    "#     n_folds=5,\n",
    "#     scoring=f1_score,\n",
    "#     threshold=0.38,\n",
    "#     random_state=42,\n",
    "#     verbose=1,\n",
    "# )\n",
    "\n",
    "\n",
    "# print(f\"Baseline F1 = {round(avg_score, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffaaf7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(\"data/optimization.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "797d68f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#               colsample_bynode=1, colsample_bytree=0.5470708466798732, gamma=0,\n",
    "#               gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
    "#               learning_rate=0.03990037419687873, max_delta_step=3, max_depth=6,\n",
    "#               min_child_weight=7, missing=nan, monotone_constraints='()',\n",
    "#               n_estimators=34, n_jobs=16, num_parallel_tree=1, random_state=42,\n",
    "#               reg_alpha=0.21369037837568203, reg_lambda=0.46481769661337713,\n",
    "#               scale_pos_weight=1, subsample=1, tree_method='exact',\n",
    "#               validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a9b004c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3973551645822644"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_0 = dict(zip(par.keys(),x0))\n",
    "par_0[\"subsample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e496641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.673868815358599\n"
     ]
    }
   ],
   "source": [
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import gp_minimize\n",
    "\n",
    "\n",
    "EARLY_STOPPING_ROUNDS = 100\n",
    "EVAL_METRIC = \"auc\"\n",
    "VERBOSE = 0\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5\n",
    "SCORING = f1_score\n",
    "THRESHOLD = 0.35\n",
    "\n",
    "\n",
    "# space = [\n",
    "#     (0.018,0.024, 'uniform'),  # learning_rate\n",
    "#     (65,85),                     # n_estimators\n",
    "#     [12,13,14],                  # max_depth\n",
    "#     (0.78,0.82),                      # subsample\n",
    "#     (0.0.5, 2., 'log-uniform'),  # min_child_weight\n",
    "#     (0.1, 0.4, 'log-uniform'),      # reg_alpha\n",
    "#     (0.2, 0.8, 'log-uniform'),    # reg_lambda\n",
    "#     (0.2, 1.0),                   # colsample_bynode\n",
    "#     (0.5, 0.8),                   # colsample_bytree\n",
    "#     [1, 2, 3],                    # num_parallel_tree\n",
    "#     (1,5),                        # max_delta_step\n",
    "# ]\n",
    "\n",
    "# space = [\n",
    "#     Real(0.0938-0.0001,0.0938+0.0001, \"log-uniform\", name=\"learning_rate\"),\n",
    "#     Integer(300-1, 300+1, \"log-uniform\",name=\"n_estimators\"),\n",
    "#     Integer(3, 4, name=\"max_depth\",),\n",
    "#     Integer(1, 2, name=\"num_parallel_tree\"),\n",
    "#     Real(1.854-0.01, 1.854+0.01, name=\"min_child_weight\"),\n",
    "#     Real(0.957 - 0.005, 0.957 + 0.005, name=\"reg_alpha\"),\n",
    "#     Real(0.724 - 0.005, 0.724 + 0.005, name=\"reg_lambda\"),\n",
    "# ]\n",
    "\n",
    "\n",
    "# space = [\n",
    "#     Real(0.0938-0.0001,0.0938+0.0001, \"log-uniform\", name=\"learning_rate\"),\n",
    "#     Integer(300-1, 300+1, \"log-uniform\",name=\"n_estimators\"),\n",
    "#     Integer(3, 4, name=\"max_depth\",),\n",
    "#     Integer(1, 2, name=\"num_parallel_tree\"),\n",
    "#     Real(1.854-0.01, 1.854+0.01, name=\"min_child_weight\"),\n",
    "#     Real(0.957 - 0.005, 0.957 + 0.005, name=\"reg_alpha\"),\n",
    "#     Real(0.724 - 0.005, 0.724 + 0.005, name=\"reg_lambda\"),\n",
    "# ]\n",
    "# par = {\n",
    "#     'learning_rate': 0.0938,\n",
    "#     'n_estimators': 300,\n",
    "#     'max_depth': 3,\n",
    "#     'num_parallel_tree': 1,\n",
    "#     'min_child_weight': 1.854,\n",
    "#     'reg_alpha': 0.957,\n",
    "#     'reg_lambda': 0.724,\n",
    "# }\n",
    "\n",
    "steps = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"n_estimators\": 1,\n",
    "    \"max_depth\": 1,\n",
    "    \"subsample\": 0.001,\n",
    "    \"min_child_weight\": 0.01,\n",
    "    \"reg_alpha\": 0.001,\n",
    "    \"reg_lambda\": 0.001,\n",
    "    \"colsample_bynode\": 0.001,\n",
    "    \"colsample_bytree\": 0.001,\n",
    "    \"num_parallel_tree\": 1,\n",
    "    \"max_delta_step\": 1,\n",
    "}\n",
    "\n",
    "results = pd.read_csv(\"data/optimization.csv\").sort_values(\"score\")\n",
    "x0 = list(results.drop([\"iteration\", \"score\"], 1).iloc[0].values)\n",
    "y0 = results[\"score\"].iloc[0]\n",
    "print(y0)\n",
    "par_0 = dict(zip(par.keys(), x0))\n",
    "\n",
    "space = [\n",
    "    Real(\n",
    "        par_0[\"learning_rate\"] - steps[\"learning_rate\"],\n",
    "        par_0[\"learning_rate\"] + steps[\"learning_rate\"],\n",
    "        \"log-uniform\",\n",
    "        name=\"learning_rate\",\n",
    "    ),\n",
    "    Integer(\n",
    "        int(par_0[\"n_estimators\"]) - steps[\"n_estimators\"],\n",
    "        int(par_0[\"n_estimators\"]) + steps[\"n_estimators\"],\n",
    "        \"log-uniform\",\n",
    "        name=\"n_estimators\",\n",
    "    ),\n",
    "    Integer(\n",
    "        int(par_0[\"max_depth\"]),\n",
    "        int(par_0[\"max_depth\"] + steps[\"max_depth\"]),\n",
    "        name=\"max_depth\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"subsample\"] - steps[\"subsample\"],\n",
    "        par_0[\"subsample\"] + steps[\"subsample\"],\n",
    "        name=\"subsample\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"min_child_weight\"] - steps[\"min_child_weight\"],\n",
    "        par_0[\"min_child_weight\"] + steps[\"min_child_weight\"],\n",
    "        name=\"min_child_weight\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"reg_alpha\"] - steps[\"reg_alpha\"],\n",
    "        par_0[\"reg_alpha\"] + steps[\"reg_alpha\"],\n",
    "        name=\"reg_alpha\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"reg_lambda\"] - steps[\"reg_lambda\"],\n",
    "        par_0[\"reg_lambda\"] + steps[\"reg_lambda\"],\n",
    "        name=\"reg_lambda\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"colsample_bynode\"] - steps[\"colsample_bynode\"],\n",
    "        par_0[\"colsample_bynode\"] + steps[\"colsample_bynode\"],\n",
    "        name=\"colsample_bynode\",\n",
    "    ),\n",
    "    Real(\n",
    "        par_0[\"colsample_bytree\"] - steps[\"colsample_bytree\"],\n",
    "        par_0[\"colsample_bytree\"] + steps[\"colsample_bytree\"],\n",
    "        name=\"colsample_bytree\",\n",
    "    ),\n",
    "    Integer(\n",
    "        int(par_0[\"num_parallel_tree\"]),\n",
    "        int(par_0[\"num_parallel_tree\"] + steps[\"num_parallel_tree\"]),\n",
    "        name=\"num_parallel_tree\",\n",
    "    ),\n",
    "    Integer(\n",
    "        int(par_0[\"max_delta_step\"]),\n",
    "        int(par_0[\"max_delta_step\"] + steps[\"max_delta_step\"]),\n",
    "        name=\"max_delta_step\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# # guardar isso de norte\n",
    "# par = {\n",
    "#     \"learning_rate\": 0.091,\n",
    "#     \"n_estimators\": 150,\n",
    "#     \"max_depth\": 4,\n",
    "#     \"subsample\": 0.4,\n",
    "#     \"min_child_weight\": 2,\n",
    "#     \"reg_alpha\": 0.2,\n",
    "#     \"reg_lambda\": 0.7,\n",
    "#     \"colsample_bynode\": 0.4,\n",
    "#     \"colsample_bytree\": 0.6,\n",
    "#     \"num_parallel_tree\": 3,\n",
    "#     \"max_delta_step\": 3,\n",
    "# }\n",
    "\n",
    "PARAMETER_NAMES = [elem.name for elem in space]\n",
    "\n",
    "\n",
    "@use_named_args(space)\n",
    "def train_function(**params):\n",
    "\n",
    "    print(f\"Testing parameters: {params.values()}\")\n",
    "\n",
    "    #     estimator = XGBClassifier(\n",
    "    #         n_jobs=n_jobs, random_state=RANDOM_STATE, **dict(zip(PARAMETER_NAMES, params))\n",
    "    #     )\n",
    "    estimator = XGBClassifier(n_jobs=n_jobs, random_state=RANDOM_STATE, **params)\n",
    "\n",
    "    fit_params = {\n",
    "        \"early_stopping_rounds\": EARLY_STOPPING_ROUNDS,\n",
    "        \"eval_metric\": EVAL_METRIC,\n",
    "        \"verbose\": VERBOSE,\n",
    "    }\n",
    "\n",
    "    return cross_validate_score(\n",
    "        X=train.drop(\"y\", 1),\n",
    "        y=train[\"y\"],\n",
    "        estimator=estimator,\n",
    "        fit_params=fit_params,\n",
    "        n_folds=N_FOLDS,\n",
    "        scoring=SCORING,\n",
    "        threshold=THRESHOLD,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3ba7974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.091, 150, 4, 0.4, 2, 0.2, 0.7, 0.4, 0.6, 3, 3]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(par.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c218aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar isso de norte\n",
    "par = {\n",
    "    \"learning_rate\": 0.091,\n",
    "    \"n_estimators\": 150,\n",
    "    \"max_depth\": 4,\n",
    "    \"subsample\": 0.4,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"reg_alpha\": 0.2,\n",
    "    \"reg_lambda\": 0.7,\n",
    "    \"colsample_bynode\": 0.4,\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"num_parallel_tree\": 3,\n",
    "    \"max_delta_step\": 3,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "314c938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = XGBClassifier(\n",
    "#     n_jobs=n_jobs,  random_state=RANDOM_STATE, **par\n",
    "# )\n",
    "\n",
    "# fit_params = {\n",
    "#     \"early_stopping_rounds\": EARLY_STOPPING_ROUNDS,\n",
    "#     \"eval_metric\": EVAL_METRIC,\n",
    "#     \"verbose\": VERBOSE,\n",
    "# }\n",
    "\n",
    "# cross_validate_score(\n",
    "#     X=train.drop(\"y\", 1),\n",
    "#     y=train[\"y\"],\n",
    "#     estimator=estimator,\n",
    "#     fit_params=fit_params,\n",
    "#     n_folds=N_FOLDS,\n",
    "#     scoring=SCORING,\n",
    "#     threshold=THRESHOLD,\n",
    "#     random_state=RANDOM_STATE,\n",
    "#     verbose=0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e6ef4e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 0.0003\n",
      "Function value obtained: -0.6739\n",
      "Current minimum: -0.6739\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Testing parameters: dict_values([0.09533046831331038, 154, 5, 0.39789785307356307, 2.014941475958356, 0.1988094158759588, 0.7029824449140873, 0.39845942912964327, 0.599224432765673, 4, 4])\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 6.2573\n",
      "Function value obtained: -0.6675\n",
      "Current minimum: -0.6739\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Testing parameters: dict_values([0.09510456469167776, 153, 5, 0.39687814191682935, 2.0154336394636605, 0.1987771355410545, 0.7043016860189045, 0.39862670473583367, 0.6004192946932296, 4, 4])\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 5.9128\n",
      "Function value obtained: -0.6663\n",
      "Current minimum: -0.6739\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Testing parameters: dict_values([0.09518556420428842, 153, 5, 0.397367389180145, 2.013217666611617, 0.19955788371001812, 0.702599190915374, 0.3992932040137017, 0.5990517848631663, 5, 3])\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 7.2577\n",
      "Function value obtained: -0.6688\n",
      "Current minimum: -0.6739\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Testing parameters: dict_values([0.09441784085093351, 153, 4, 0.396647992372498, 2.010199981645154, 0.19984584941243222, 0.7032872756808208, 0.3995721300907767, 0.6004838173428608, 4, 4])\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 4.9286\n",
      "Function value obtained: -0.6691\n",
      "Current minimum: -0.6739\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Testing parameters: dict_values([0.09545136910107542, 152, 4, 0.3977047218784317, 2.014626815396946, 0.1986907469193901, 0.7024642265539439, 0.39961455129092305, 0.6005970187137618, 5, 4])\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 6.0150\n",
      "Function value obtained: -0.6695\n",
      "Current minimum: -0.6739\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Testing parameters: dict_values([0.0961403566517729, 153, 4, 0.3971527446005716, 2.0149404040452743, 0.19871666769105117, 0.7037368803455164, 0.39898040665914697, 0.6002358111405647, 5, 4])\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 6.6587\n",
      "Function value obtained: -0.6682\n",
      "Current minimum: -0.6739\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Testing parameters: dict_values([0.09417671902053411, 153, 5, 0.39814723960099413, 2.0200340714495804, 0.1990599012148132, 0.7024988050884016, 0.39924832160405027, 0.5987190955073304, 4, 4])\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 6.7766\n",
      "Function value obtained: -0.6667\n",
      "Current minimum: -0.6739\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Testing parameters: dict_values([0.09486391014371671, 153, 5, 0.3979643013745, 2.0208349113498794, 0.19847429673662847, 0.7035177534342082, 0.4000762082976192, 0.5996970580978468, 5, 4])\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 8.1267\n",
      "Function value obtained: -0.6692\n",
      "Current minimum: -0.6739\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Testing parameters: dict_values([0.09431448402227716, 153, 4, 0.3978880337553303, 2.0154136848263877, 0.19972342469976812, 0.7029168360295653, 0.39914164468052565, 0.5997847631362879, 4, 3])\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 5.4744\n",
      "Function value obtained: -0.6705\n",
      "Current minimum: -0.6739\n",
      "Testing parameters: dict_values([0.09444011878493902, 153, 5, 0.39678030247009183, 2.011135963262278, 0.19955286584910348, 0.7031795722518451, 0.40013807995002654, 0.5999569623289754, 5, 4])\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 15.2146\n",
      "Function value obtained: -0.6669\n",
      "Current minimum: -0.6739\n",
      "Best found params: [0.0951498561975138, 153.0, 4.0, 0.3972033495959948, 2.012470202022637, 0.1990406524613734, 0.7033873757009984, 0.3993460031750084, 0.5996791201765128, 4.0, 3.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>colsample_bynode</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>num_parallel_tree</th>\n",
       "      <th>max_delta_step</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.095150</td>\n",
       "      <td>153.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.397203</td>\n",
       "      <td>2.012470</td>\n",
       "      <td>0.199041</td>\n",
       "      <td>0.703387</td>\n",
       "      <td>0.399346</td>\n",
       "      <td>0.599679</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.673869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.094314</td>\n",
       "      <td>153.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.397888</td>\n",
       "      <td>2.015414</td>\n",
       "      <td>0.199723</td>\n",
       "      <td>0.702917</td>\n",
       "      <td>0.399142</td>\n",
       "      <td>0.599785</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.670507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.095451</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.397705</td>\n",
       "      <td>2.014627</td>\n",
       "      <td>0.198691</td>\n",
       "      <td>0.702464</td>\n",
       "      <td>0.399615</td>\n",
       "      <td>0.600597</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.669532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.094864</td>\n",
       "      <td>153.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.397964</td>\n",
       "      <td>2.020835</td>\n",
       "      <td>0.198474</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.400076</td>\n",
       "      <td>0.599697</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.669216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.094418</td>\n",
       "      <td>153.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>2.010200</td>\n",
       "      <td>0.199846</td>\n",
       "      <td>0.703287</td>\n",
       "      <td>0.399572</td>\n",
       "      <td>0.600484</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.669123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.095186</td>\n",
       "      <td>153.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.397367</td>\n",
       "      <td>2.013218</td>\n",
       "      <td>0.199558</td>\n",
       "      <td>0.702599</td>\n",
       "      <td>0.399293</td>\n",
       "      <td>0.599052</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.668750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.096140</td>\n",
       "      <td>153.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.397153</td>\n",
       "      <td>2.014940</td>\n",
       "      <td>0.198717</td>\n",
       "      <td>0.703737</td>\n",
       "      <td>0.398980</td>\n",
       "      <td>0.600236</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.668190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.095330</td>\n",
       "      <td>154.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.397898</td>\n",
       "      <td>2.014941</td>\n",
       "      <td>0.198809</td>\n",
       "      <td>0.702982</td>\n",
       "      <td>0.398459</td>\n",
       "      <td>0.599224</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.667464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.094440</td>\n",
       "      <td>153.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.396780</td>\n",
       "      <td>2.011136</td>\n",
       "      <td>0.199553</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.400138</td>\n",
       "      <td>0.599957</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.666865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.094177</td>\n",
       "      <td>153.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.398147</td>\n",
       "      <td>2.020034</td>\n",
       "      <td>0.199060</td>\n",
       "      <td>0.702499</td>\n",
       "      <td>0.399248</td>\n",
       "      <td>0.598719</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.666663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.095105</td>\n",
       "      <td>153.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.396878</td>\n",
       "      <td>2.015434</td>\n",
       "      <td>0.198777</td>\n",
       "      <td>0.704302</td>\n",
       "      <td>0.398627</td>\n",
       "      <td>0.600419</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.666338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration  learning_rate  n_estimators  max_depth  subsample  \\\n",
       "0           0       0.095150         153.0        4.0   0.397203   \n",
       "9           9       0.094314         153.0        4.0   0.397888   \n",
       "5           5       0.095451         152.0        4.0   0.397705   \n",
       "8           8       0.094864         153.0        5.0   0.397964   \n",
       "4           4       0.094418         153.0        4.0   0.396648   \n",
       "3           3       0.095186         153.0        5.0   0.397367   \n",
       "6           6       0.096140         153.0        4.0   0.397153   \n",
       "1           1       0.095330         154.0        5.0   0.397898   \n",
       "10         10       0.094440         153.0        5.0   0.396780   \n",
       "7           7       0.094177         153.0        5.0   0.398147   \n",
       "2           2       0.095105         153.0        5.0   0.396878   \n",
       "\n",
       "    min_child_weight  reg_alpha  reg_lambda  colsample_bynode  \\\n",
       "0           2.012470   0.199041    0.703387          0.399346   \n",
       "9           2.015414   0.199723    0.702917          0.399142   \n",
       "5           2.014627   0.198691    0.702464          0.399615   \n",
       "8           2.020835   0.198474    0.703518          0.400076   \n",
       "4           2.010200   0.199846    0.703287          0.399572   \n",
       "3           2.013218   0.199558    0.702599          0.399293   \n",
       "6           2.014940   0.198717    0.703737          0.398980   \n",
       "1           2.014941   0.198809    0.702982          0.398459   \n",
       "10          2.011136   0.199553    0.703180          0.400138   \n",
       "7           2.020034   0.199060    0.702499          0.399248   \n",
       "2           2.015434   0.198777    0.704302          0.398627   \n",
       "\n",
       "    colsample_bytree  num_parallel_tree  max_delta_step     score  \n",
       "0           0.599679                4.0             3.0 -0.673869  \n",
       "9           0.599785                4.0             3.0 -0.670507  \n",
       "5           0.600597                5.0             4.0 -0.669532  \n",
       "8           0.599697                5.0             4.0 -0.669216  \n",
       "4           0.600484                4.0             4.0 -0.669123  \n",
       "3           0.599052                5.0             3.0 -0.668750  \n",
       "6           0.600236                5.0             4.0 -0.668190  \n",
       "1           0.599224                4.0             4.0 -0.667464  \n",
       "10          0.599957                5.0             4.0 -0.666865  \n",
       "7           0.598719                4.0             4.0 -0.666663  \n",
       "2           0.600419                4.0             4.0 -0.666338  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 15s, sys: 3.33 s, total: 16min 18s\n",
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "N_CALLS = 10\n",
    "# res_gp = forest_minimize(\n",
    "#     train_function,\n",
    "#     space,\n",
    "#     base_estimator=\"RF\",\n",
    "#     random_state=0,\n",
    "#     verbose=1,\n",
    "#     n_calls=11,\n",
    "#     n_random_starts=10,\n",
    "#     n_jobs=n_jobs,\n",
    "# )\n",
    "\n",
    "\n",
    "results = pd.read_csv(\"data/optimization.csv\").sort_values('score')\n",
    "x0 = list(results.drop([\"iteration\", \"score\"], 1).iloc[0].values)\n",
    "y0 = results[\"score\"].iloc[0]\n",
    "\n",
    "\n",
    "res_gp = gp_minimize(\n",
    "    train_function,\n",
    "    space,\n",
    "    x0=x0,\n",
    "    y0=y0,\n",
    "    random_state=0,\n",
    "    verbose=1,\n",
    "    n_calls=N_CALLS,\n",
    "    n_random_starts=10,\n",
    "    n_jobs=n_jobs,\n",
    ")\n",
    "\n",
    "xgb_best_params = res_gp.x\n",
    "\n",
    "print(f\"Best found params: {xgb_best_params}\")\n",
    "\n",
    "plot_convergence(res_gp)\n",
    "\n",
    "results = (\n",
    "    pd.DataFrame(res_gp.x_iters, columns=PARAMETER_NAMES)\n",
    "    .assign(score=res_gp.func_vals)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"iteration\"})\n",
    "    .sort_values(\"score\")\n",
    ")\n",
    "\n",
    "results.to_csv(\"data/optimization.csv\", index=False, mode='a',header=False)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "43a6448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7816011f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.673868815358599"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(\"data/optimization.csv\").sort_values(\"score\")\n",
    "x0 = list(results.drop([\"iteration\", \"score\"], 1).iloc[0].values)\n",
    "y0 = results[\"score\"].iloc[0]\n",
    "\n",
    "\n",
    "params = dict(zip(PARAMETER_NAMES, x0))\n",
    "\n",
    "for col in [\"n_estimators\", \"max_depth\", \"num_parallel_tree\"]:    \n",
    "    if col in params:\n",
    "        params[col] = int(params[col])\n",
    "\n",
    "\n",
    "estimator = XGBClassifier(n_jobs=n_jobs, random_state=RANDOM_STATE, **params)\n",
    "\n",
    "fit_params = {\n",
    "    \"early_stopping_rounds\": EARLY_STOPPING_ROUNDS,\n",
    "    \"eval_metric\": EVAL_METRIC,\n",
    "    \"verbose\": VERBOSE,\n",
    "}\n",
    "\n",
    "cross_validate_score(\n",
    "    X=train.drop(\"y\", 1),\n",
    "    y=train[\"y\"],\n",
    "    estimator=estimator,\n",
    "    fit_params=fit_params,\n",
    "    n_folds=N_FOLDS,\n",
    "    scoring=SCORING,\n",
    "    threshold=THRESHOLD,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4d5dc8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:42:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "def predict(model, X_test, threshold=0.5):\n",
    "    predict_prob = model.predict_proba(X_test)[:, 1]\n",
    "    condition = lambda x: x > threshold\n",
    "    vec_condition = np.vectorize(condition)\n",
    "    return np.where(vec_condition(predict_prob), 1.0, 0.0)\n",
    "\n",
    "estimator.fit(X=train.drop(\"y\", 1), y=train[\"y\"])\n",
    "\n",
    "\n",
    "\n",
    "y_pred = predict(estimator, test, threshold=THRESHOLD).astype(int)\n",
    "\n",
    "pd.read_csv(\"submission-12.csv\")[[\"id\"]].assign(predicted=y_pred).to_csv(\"submission-14.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "df04902a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>var10</th>\n",
       "      <th>var11</th>\n",
       "      <th>var12</th>\n",
       "      <th>var13</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>var17</th>\n",
       "      <th>var18</th>\n",
       "      <th>var19</th>\n",
       "      <th>var20</th>\n",
       "      <th>var21</th>\n",
       "      <th>var22</th>\n",
       "      <th>var23</th>\n",
       "      <th>var24</th>\n",
       "      <th>var25</th>\n",
       "      <th>var26</th>\n",
       "      <th>var27</th>\n",
       "      <th>var28</th>\n",
       "      <th>var29</th>\n",
       "      <th>var30</th>\n",
       "      <th>var31</th>\n",
       "      <th>var32</th>\n",
       "      <th>var33</th>\n",
       "      <th>var34</th>\n",
       "      <th>var35</th>\n",
       "      <th>var36</th>\n",
       "      <th>var37</th>\n",
       "      <th>var38</th>\n",
       "      <th>var39</th>\n",
       "      <th>var40</th>\n",
       "      <th>var41</th>\n",
       "      <th>var42</th>\n",
       "      <th>var43</th>\n",
       "      <th>var44</th>\n",
       "      <th>var45</th>\n",
       "      <th>var46</th>\n",
       "      <th>var47</th>\n",
       "      <th>var48</th>\n",
       "      <th>var49</th>\n",
       "      <th>var50</th>\n",
       "      <th>var51</th>\n",
       "      <th>var52</th>\n",
       "      <th>var53</th>\n",
       "      <th>var54</th>\n",
       "      <th>var55</th>\n",
       "      <th>var56</th>\n",
       "      <th>var57</th>\n",
       "      <th>var58</th>\n",
       "      <th>var59</th>\n",
       "      <th>var60</th>\n",
       "      <th>var61</th>\n",
       "      <th>var62</th>\n",
       "      <th>var63</th>\n",
       "      <th>var64</th>\n",
       "      <th>var65</th>\n",
       "      <th>var66</th>\n",
       "      <th>var67</th>\n",
       "      <th>var68</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>1353</td>\n",
       "      <td>28956</td>\n",
       "      <td>743</td>\n",
       "      <td>1289</td>\n",
       "      <td>27</td>\n",
       "      <td>-999</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4530</td>\n",
       "      <td>914</td>\n",
       "      <td>991</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1155</td>\n",
       "      <td>19</td>\n",
       "      <td>1031</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>413</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217528</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.367742</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.201839</td>\n",
       "      <td>0.353965</td>\n",
       "      <td>0.166641</td>\n",
       "      <td>0.049108</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.016683</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.253676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>1446</td>\n",
       "      <td>7803</td>\n",
       "      <td>5151</td>\n",
       "      <td>935</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>8731</td>\n",
       "      <td>1341</td>\n",
       "      <td>2033</td>\n",
       "      <td>26</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>1299</td>\n",
       "      <td>26</td>\n",
       "      <td>773</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>692</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221968</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.177047</td>\n",
       "      <td>0.072127</td>\n",
       "      <td>0.074555</td>\n",
       "      <td>0.217009</td>\n",
       "      <td>0.144403</td>\n",
       "      <td>0.892028</td>\n",
       "      <td>0.038323</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.099265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>243</td>\n",
       "      <td>4325</td>\n",
       "      <td>1109</td>\n",
       "      <td>1903</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>10131</td>\n",
       "      <td>914</td>\n",
       "      <td>1503</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>1294</td>\n",
       "      <td>24</td>\n",
       "      <td>1562</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>553</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.213224</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.101075</td>\n",
       "      <td>0.210879</td>\n",
       "      <td>0.324770</td>\n",
       "      <td>0.384992</td>\n",
       "      <td>0.330680</td>\n",
       "      <td>0.072864</td>\n",
       "      <td>0.930373</td>\n",
       "      <td>0.021052</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.136029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>419</td>\n",
       "      <td>743</td>\n",
       "      <td>7750</td>\n",
       "      <td>183</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>636</td>\n",
       "      <td>5879</td>\n",
       "      <td>146</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>811</td>\n",
       "      <td>26</td>\n",
       "      <td>152</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>662</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.205044</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.131070</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.244936</td>\n",
       "      <td>0.158088</td>\n",
       "      <td>0.986882</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.220588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>1863</td>\n",
       "      <td>22693</td>\n",
       "      <td>5625</td>\n",
       "      <td>965</td>\n",
       "      <td>9</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>24967</td>\n",
       "      <td>4427</td>\n",
       "      <td>772</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.024989</td>\n",
       "      <td>0.225166</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>0.252794</td>\n",
       "      <td>0.080405</td>\n",
       "      <td>0.944501</td>\n",
       "      <td>0.021806</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.113971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21178</th>\n",
       "      <td>35297</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>1460</td>\n",
       "      <td>13335</td>\n",
       "      <td>9048</td>\n",
       "      <td>620</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>13567</td>\n",
       "      <td>2617</td>\n",
       "      <td>572</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1573</td>\n",
       "      <td>26</td>\n",
       "      <td>592</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>332</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.213106</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.387701</td>\n",
       "      <td>0.148933</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.326307</td>\n",
       "      <td>0.132833</td>\n",
       "      <td>0.968718</td>\n",
       "      <td>0.039626</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.253676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21179</th>\n",
       "      <td>35298</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>532</td>\n",
       "      <td>14837</td>\n",
       "      <td>2590</td>\n",
       "      <td>855</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>15367</td>\n",
       "      <td>2261</td>\n",
       "      <td>678</td>\n",
       "      <td>19</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>1383</td>\n",
       "      <td>19</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>578</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.210435</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.101075</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.179243</td>\n",
       "      <td>0.205030</td>\n",
       "      <td>0.229354</td>\n",
       "      <td>0.052108</td>\n",
       "      <td>0.940464</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.209559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21180</th>\n",
       "      <td>35300</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>2923</td>\n",
       "      <td>16685</td>\n",
       "      <td>3162</td>\n",
       "      <td>1604</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>17658</td>\n",
       "      <td>4369</td>\n",
       "      <td>1279</td>\n",
       "      <td>26</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>971</td>\n",
       "      <td>26</td>\n",
       "      <td>1334</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>74</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.218353</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.367742</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.237607</td>\n",
       "      <td>0.810448</td>\n",
       "      <td>0.179781</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>0.745711</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.161765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21181</th>\n",
       "      <td>35302</td>\n",
       "      <td>5</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>367</td>\n",
       "      <td>7637</td>\n",
       "      <td>1389</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>28370</td>\n",
       "      <td>679</td>\n",
       "      <td>1117</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>868</td>\n",
       "      <td>26</td>\n",
       "      <td>1158</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.224865</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.246237</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.102662</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.149598</td>\n",
       "      <td>0.032583</td>\n",
       "      <td>0.891019</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.246324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21182</th>\n",
       "      <td>35303</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>1446</td>\n",
       "      <td>6031</td>\n",
       "      <td>853</td>\n",
       "      <td>829</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3182</td>\n",
       "      <td>5360</td>\n",
       "      <td>1910</td>\n",
       "      <td>26</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1473</td>\n",
       "      <td>26</td>\n",
       "      <td>675</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>89</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.207270</td>\n",
       "      <td>0.031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020069</td>\n",
       "      <td>0.313769</td>\n",
       "      <td>0.092545</td>\n",
       "      <td>0.285876</td>\n",
       "      <td>0.079940</td>\n",
       "      <td>0.901110</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21183 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  var1  var2  var3   var4  var5  var6  var7  var8  var9  var10  \\\n",
       "0          0     5   126  1353  28956   743  1289    27  -999     1     33   \n",
       "1          2     6   126  1446   7803  5151   935    35  -999     3     63   \n",
       "2          4     5    44   243   4325  1109  1903    33    24     1     63   \n",
       "3          7     4    53   419    743  7750   183    35  -999     3     14   \n",
       "4         15     4   126  1863  22693  5625   965     9  -999     3     63   \n",
       "...      ...   ...   ...   ...    ...   ...   ...   ...   ...   ...    ...   \n",
       "21178  35297     4   126  1460  13335  9048   620    35    27     3     63   \n",
       "21179  35298    18    19   532  14837  2590   855    27    20     3     63   \n",
       "21180  35300     4   126  2923  16685  3162  1604    35  -999     3     63   \n",
       "21181  35302     5  -999  -999    367  7637  1389    35  -999     3     63   \n",
       "21182  35303     6   126  1446   6031   853   829    35    27     3     14   \n",
       "\n",
       "       var11  var12  var13  var14  var15  var16  var17  var18  var19  var20  \\\n",
       "0       4530    914    991     19      1      3      3      3   1155     19   \n",
       "1       8731   1341   2033     26     58     58     22      5   1299     26   \n",
       "2      10131    914   1503     24     60     61     23      5   1294     24   \n",
       "3        636   5879    146     26     22     22     10      4    811     26   \n",
       "4      24967   4427    772      5     73     73     29      5    595      5   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "21178  13567   2617    572     26     37     35     11      4   1573     26   \n",
       "21179  15367   2261    678     19   -999   -999   -999   -999   1383     19   \n",
       "21180  17658   4369   1279     26   -999   -999   -999   -999    971     26   \n",
       "21181  28370    679   1117     26     34     34     10      4    868     26   \n",
       "21182   3182   5360   1910     26     55     56     20      5   1473     26   \n",
       "\n",
       "       var21  var22  var23  var24  var25  var26  var27  var28  var29  var30  \\\n",
       "0       1031      5      3      2      3      7      0     25      4      1   \n",
       "1        773      5      3      1      2      1      0     25      4      0   \n",
       "2       1562      5      4      1      0      1      0     26      5      2   \n",
       "3        152      5      3      2      4      4      0     24      4      2   \n",
       "4        796      0      1      0      1      7      0     11      2      1   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "21178    592      5      3      2      1      1      0     24      4      1   \n",
       "21179    700      0      3      2      1   -999      0     25      4      1   \n",
       "21180   1334      5      3      0      1   -999      0     24      4      1   \n",
       "21181   1158      5      3      2      1      9      0     24      4      1   \n",
       "21182    675      5      3      2      1      7      1     24      4      1   \n",
       "\n",
       "       var31  var32  var33  var34  var35  var36  var37  var38  var39  var40  \\\n",
       "0          0     11      2     62    413     27      0      0      4      6   \n",
       "1          1      6      5     58    692     21     15      8      4      0   \n",
       "2          0     17      0     12    553      0     18      0      4     10   \n",
       "3          0     12      5     38    662     28      1      0      4      9   \n",
       "4          0     21      3     18    546      0      1      0      4      6   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "21178      0     21      6     42    332     21     20      9      1     11   \n",
       "21179      0     20      0     60    578      2      0      0      4      2   \n",
       "21180      0     12      5     49     74     28      2      0      4      4   \n",
       "21181      0     15      5     54    434      0      1      0      4     19   \n",
       "21182      0     15      6     33     89     31      4      0      4     16   \n",
       "\n",
       "       var41  var42  var43  var44  var45  var46  var47  var48  var49  var50  \\\n",
       "0          3     24      3      1      0      0      0      0      0      0   \n",
       "1          1     30      0      1      0      0      0      0      0      0   \n",
       "2          3     26     14      1      0      0      0      0      0      0   \n",
       "3          3     28      7      1      0      0      0      0      0      1   \n",
       "4          3     28      8      1      0      0      0      0      1      0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "21178      3     25     13      1      0      0      0      0      0      0   \n",
       "21179      3     26      6      1      0      0      0      0      0      0   \n",
       "21180      3     19      4      1      0      0      0      0      0      0   \n",
       "21181      3     23      6      1      0      0      0      0      0      0   \n",
       "21182      3     22     11      1      0      0      0      0      0      0   \n",
       "\n",
       "       var51  var52  var53  var54     var55  var56     var57       var58  \\\n",
       "0          0     44      1      1  0.217528  0.272  0.367742    0.062900   \n",
       "1          0     13      1      1  0.221968  0.853  0.053763    0.177047   \n",
       "2          0     36      1      1  0.213224  0.632  0.101075    0.210879   \n",
       "3          0     13      1      1  0.205044  0.117  0.935484    0.007068   \n",
       "4          0     51      1      1  0.203750  0.079  0.967742    0.024989   \n",
       "...      ...    ...    ...    ...       ...    ...       ...         ...   \n",
       "21178      0     34      2      2  0.213106  0.065  0.967742    0.387701   \n",
       "21179      0     10      2      2  0.210435  0.740  0.101075 -999.000000   \n",
       "21180      0     39      2      2  0.218353  0.288  0.367742 -999.000000   \n",
       "21181      0      3      2      2  0.224865  0.324  0.246237    0.199008   \n",
       "21182      0     19      2      2  0.207270  0.031  1.000000    0.020069   \n",
       "\n",
       "          var59       var60     var61     var62     var63     var64  var65  \\\n",
       "0      0.201839    0.353965  0.166641  0.049108  0.986882  0.016683 -999.0   \n",
       "1      0.072127    0.074555  0.217009  0.144403  0.892028  0.038323 -999.0   \n",
       "2      0.324770    0.384992  0.330680  0.072864  0.930373  0.021052 -999.0   \n",
       "3      0.131070 -999.000000  0.244936  0.158088  0.986882  0.022649 -999.0   \n",
       "4      0.225166    0.059940  0.252794  0.080405  0.944501  0.021806 -999.0   \n",
       "...         ...         ...       ...       ...       ...       ...    ...   \n",
       "21178  0.148933 -999.000000  0.326307  0.132833  0.968718  0.039626 -999.0   \n",
       "21179  0.179243    0.205030  0.229354  0.052108  0.940464  0.016952 -999.0   \n",
       "21180  0.237607    0.810448  0.179781  0.029155  0.745711  0.020158 -999.0   \n",
       "21181  0.102662 -999.000000  0.149598  0.032583  0.891019  0.012596 -999.0   \n",
       "21182  0.313769    0.092545  0.285876  0.079940  0.901110  0.026239 -999.0   \n",
       "\n",
       "       var66       var67     var68  \n",
       "0     -999.0    0.176471  0.253676  \n",
       "1     -999.0    0.147059  0.099265  \n",
       "2     -999.0    0.294118  0.136029  \n",
       "3     -999.0    0.294118  0.220588  \n",
       "4     -999.0    0.352941  0.113971  \n",
       "...      ...         ...       ...  \n",
       "21178 -999.0    0.323529  0.253676  \n",
       "21179 -999.0    0.088235  0.209559  \n",
       "21180 -999.0    0.205882  0.161765  \n",
       "21181 -999.0 -999.000000  0.246324  \n",
       "21182 -999.0    0.191176  0.312500  \n",
       "\n",
       "[21183 rows x 69 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6b2cc044",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = estimator.predict(test.drop(\"y\", 1)).astype(int)\n",
    "\n",
    "\n",
    "pd.read_csv(\"submission-12.csv\")[[\"id\"]].assign(predicted=y_pred).to_csv(\"submission-13.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "95429101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T15:20:24.232347Z",
     "iopub.status.busy": "2021-08-29T15:20:24.231538Z",
     "iopub.status.idle": "2021-08-29T15:41:07.571615Z",
     "shell.execute_reply": "2021-08-29T15:41:07.570907Z",
     "shell.execute_reply.started": "2021-08-29T15:18:48.699322Z"
    },
    "papermill": {
     "duration": 1243.376702,
     "end_time": "2021-08-29T15:41:07.571822",
     "exception": false,
     "start_time": "2021-08-29T15:20:24.195120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train_func(params):\n",
    "#     \"\"\" training funcion that will be optimised \"\"\"\n",
    "#     learning_rate = params[0]\n",
    "#     max_depth = params[1]\n",
    "#     min_child_weight=params[2]\n",
    "#     subsample = params[3]\n",
    "#     colsample_bynode = params[4]\n",
    "#     num_parallel_tree = params[5]\n",
    "#     print(f\"Testing parameters: {params}\")\n",
    "    \n",
    "#     scores = []\n",
    "#     for fold in range(5):\n",
    "#         train_data = train[train.fold != fold].copy()\n",
    "#         test_data = train[train.fold == fold].copy()\n",
    "#         X_train = train_data.drop(columns=['fold', 'y']).values\n",
    "#         X_test = test_data.drop(columns=['fold', 'y']).values\n",
    "#         y_train = train_data['y'].values\n",
    "#         y_test = test_data['y'].values\n",
    "\n",
    "        \n",
    "#         fit_params = {\n",
    "#             'early_stopping_rounds': 100,\n",
    "#             'eval_metric' : 'auc',\n",
    "#             'eval_set': [(X_test, y_test)],\n",
    "#             'verbose': False,\n",
    "#         }\n",
    "\n",
    "#         xgb = XGBClassifier(\n",
    "#             n_jobs=-1,\n",
    "#             eval_metric='auc',\n",
    "#             random_state=0,\n",
    "#             n_estimators=100,  # you should tune n_estimators aswell\n",
    "#             learning_rate=learning_rate,\n",
    "#             max_depth=max_depth,\n",
    "#             min_child_weight=min_child_weight,\n",
    "#             subsample=subsample,\n",
    "#             colsample_bynode=colsample_bynode,\n",
    "#             num_parallel_tree=num_parallel_tree\n",
    "#         )\n",
    "        \n",
    "#         xgb.fit(X_train, y_train, **fit_params)\n",
    "#         p = xgb.predict_proba(X_test)[:, -1]\n",
    "#         scores.append(metrics.roc_auc_score(y_test, p))\n",
    "        \n",
    "#     avg_score = np.mean(scores)\n",
    "#     return -avg_score  # metric that will be minimized, since a bigger auc is better, we negate it\n",
    "\n",
    "# space = [\n",
    "#     (1e-3, 9e-1, 'log-uniform'),  # learning_rate\n",
    "#     (3, 30),  # max_depth\n",
    "#     (0.01, 20.0, 'log-uniform'),  # min_child_weight\n",
    "#     (0.2, 1.0),  # subsample\n",
    "#     (0.2, 1.0),  # colsample_bynode\n",
    "#     [1, 2, 3],  # num_parallel_tree\n",
    "# ]\n",
    "\n",
    "# res_gp = forest_minimize(train_func, space, base_estimator='RF', random_state=0, verbose=1, n_calls=50, n_random_starts=10)\n",
    "# xgb_best_params = res_gp.x\n",
    "# print(f\"Best found params: {xgb_best_params}\") \n",
    "# plot_convergence(res_gp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05493b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee55d2e9",
   "metadata": {
    "papermill": {
     "duration": 0.029771,
     "end_time": "2021-08-29T15:41:07.632066",
     "exception": false,
     "start_time": "2021-08-29T15:41:07.602295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Applying learning rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "707b65c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T15:41:07.704007Z",
     "iopub.status.busy": "2021-08-29T15:41:07.703329Z",
     "iopub.status.idle": "2021-08-29T15:41:07.706335Z",
     "shell.execute_reply": "2021-08-29T15:41:07.705761Z"
    },
    "papermill": {
     "duration": 0.04448,
     "end_time": "2021-08-29T15:41:07.706503",
     "exception": false,
     "start_time": "2021-08-29T15:41:07.662023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting the best found LR as base\n",
    "def xgb_learning_rate_decay_power_099(boosting_round, num_boost_round):\n",
    "    base_learning_rate = xgb_best_params[0]\n",
    "    lr = base_learning_rate  * np.power(.99, boosting_round)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def xgb_learning_rate_decay_power_0995(boosting_round, num_boost_round):\n",
    "    base_learning_rate = xgb_best_params[0]\n",
    "    lr = base_learning_rate  * np.power(.995, boosting_round)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def xgb_learning_rate_decay_power_095(boosting_round, num_boost_round):\n",
    "    base_learning_rate = xgb_best_params[0]\n",
    "    lr = base_learning_rate  * np.power(.95, boosting_round)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "# testing some default values\n",
    "def xgb_learning_rate_010_decay_power_099(boosting_round, num_boost_round):\n",
    "    base_learning_rate = 0.1\n",
    "    lr = base_learning_rate  * np.power(.99, boosting_round)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def xgb_learning_rate_010_decay_power_0995(boosting_round, num_boost_round):\n",
    "    base_learning_rate = 0.1\n",
    "    lr = base_learning_rate  * np.power(.995, boosting_round)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def xgb_learning_rate_010_decay_power_095(boosting_round, num_boost_round):\n",
    "    base_learning_rate = 0.1\n",
    "    lr = base_learning_rate  * np.power(.95, boosting_round)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def xgb_learning_rate_050_decay_power_099(boosting_round, num_boost_round):\n",
    "    base_learning_rate = 0.05\n",
    "    lr = base_learning_rate  * np.power(.99, boosting_round)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def xgb_learning_rate_050_decay_power_0995(boosting_round, num_boost_round):\n",
    "    base_learning_rate = 0.05\n",
    "    lr = base_learning_rate  * np.power(.995, boosting_round)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def xgb_learning_rate_050_decay_power_095(boosting_round, num_boost_round):\n",
    "    base_learning_rate = 0.05\n",
    "    lr = base_learning_rate  * np.power(.95, boosting_round)\n",
    "    return lr if lr > 1e-3 else 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "859accda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6193136536010251"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poss_cbs = {\n",
    "    0: [xgboost.callback.reset_learning_rate(xgb_learning_rate_decay_power_099)],\n",
    "    1: [xgboost.callback.reset_learning_rate(xgb_learning_rate_decay_power_0995)],\n",
    "    2: [xgboost.callback.reset_learning_rate(xgb_learning_rate_decay_power_095)],\n",
    "    3: [xgboost.callback.reset_learning_rate(xgb_learning_rate_010_decay_power_099)],\n",
    "    4: [xgboost.callback.reset_learning_rate(xgb_learning_rate_010_decay_power_0995)],\n",
    "    5: [xgboost.callback.reset_learning_rate(xgb_learning_rate_010_decay_power_095)],\n",
    "    6: [xgboost.callback.reset_learning_rate(xgb_learning_rate_050_decay_power_099)],\n",
    "    7: [xgboost.callback.reset_learning_rate(xgb_learning_rate_050_decay_power_0995)],\n",
    "    8: [xgboost.callback.reset_learning_rate(xgb_learning_rate_050_decay_power_095)],\n",
    "}\n",
    "\n",
    "results = pd.read_csv(\"data/optimization.csv\").sort_values(\"score\")\n",
    "x0 = list(results.drop([\"iteration\", \"score\"], 1).iloc[0].values)\n",
    "y0 = results[\"score\"].iloc[0]\n",
    "\n",
    "params = dict(zip(PARAMETER_NAMES, x0))\n",
    "\n",
    "for col in [\"n_estimators\", \"max_depth\", \"num_parallel_tree\"]:\n",
    "    if col in params:\n",
    "        params[col] = int(params[col])\n",
    "\n",
    "estimator = XGBClassifier(n_jobs=n_jobs, random_state=RANDOM_STATE, **params)\n",
    "\n",
    "fit_params = {\n",
    "    \"early_stopping_rounds\": EARLY_STOPPING_ROUNDS,\n",
    "    \"eval_metric\": EVAL_METRIC,\n",
    "    \"verbose\": VERBOSE,\n",
    "    \"callbacks\": poss_cbs[8],\n",
    "}\n",
    "\n",
    "cross_validate_score(\n",
    "    X=train.drop(\"y\", 1),\n",
    "    y=train[\"y\"],\n",
    "    estimator=estimator,\n",
    "    fit_params=fit_params,\n",
    "    n_folds=N_FOLDS,\n",
    "    scoring=SCORING,\n",
    "    threshold=THRESHOLD,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc1881b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T15:41:07.771420Z",
     "iopub.status.busy": "2021-08-29T15:41:07.770744Z",
     "iopub.status.idle": "2021-08-29T15:42:05.493357Z",
     "shell.execute_reply": "2021-08-29T15:42:05.494300Z"
    },
    "papermill": {
     "duration": 57.757178,
     "end_time": "2021-08-29T15:42:05.494517",
     "exception": false,
     "start_time": "2021-08-29T15:41:07.737339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callback: 0, auc = 0.8893\n",
      "Callback: 1, auc = 0.8891\n",
      "Callback: 2, auc = 0.8855\n",
      "Callback: 3, auc = 0.8832\n",
      "Callback: 4, auc = 0.8852\n",
      "Callback: 5, auc = 0.8675\n",
      "Callback: 6, auc = 0.873\n",
      "Callback: 7, auc = 0.876\n",
      "Callback: 8, auc = 0.8621\n"
     ]
    }
   ],
   "source": [
    "# could have been a part of the hyper parameter search, but here I will be tuning it only for the best model \n",
    "learning_rate = xgb_best_params[0]\n",
    "max_depth = xgb_best_params[1]\n",
    "min_child_weight = xgb_best_params[2]\n",
    "subsample = xgb_best_params[3]\n",
    "colsample_bynode = xgb_best_params[4]\n",
    "num_parallel_tree = xgb_best_params[5]\n",
    "\n",
    "poss_cbs = {\n",
    "    0: [xgboost.callback.reset_learning_rate(xgb_learning_rate_decay_power_099)],\n",
    "    1: [xgboost.callback.reset_learning_rate(xgb_learning_rate_decay_power_0995)],\n",
    "    2: [xgboost.callback.reset_learning_rate(xgb_learning_rate_decay_power_095)],\n",
    "    3: [xgboost.callback.reset_learning_rate(xgb_learning_rate_010_decay_power_099)],\n",
    "    4: [xgboost.callback.reset_learning_rate(xgb_learning_rate_010_decay_power_0995)],\n",
    "    5: [xgboost.callback.reset_learning_rate(xgb_learning_rate_010_decay_power_095)],\n",
    "    6: [xgboost.callback.reset_learning_rate(xgb_learning_rate_050_decay_power_099)],\n",
    "    7: [xgboost.callback.reset_learning_rate(xgb_learning_rate_050_decay_power_0995)],\n",
    "    8: [xgboost.callback.reset_learning_rate(xgb_learning_rate_050_decay_power_095)]\n",
    "}\n",
    "\n",
    "# trying different lr decay callbacks\n",
    "best_cb = None\n",
    "best_score = 0\n",
    "for cb in poss_cbs:\n",
    "    scores = []\n",
    "    for fold in range(5):\n",
    "        train_data = train[train.fold != fold].copy()\n",
    "        test_data = train[train.fold == fold].copy()\n",
    "        X_train = train_data.drop(columns=['fold', 'y']).values\n",
    "        X_test = test_data.drop(columns=['fold', 'y']).values\n",
    "        y_train = train_data['y'].values\n",
    "        y_test = test_data['y'].values\n",
    "\n",
    "        fit_params = {\n",
    "            'early_stopping_rounds': 1000,\n",
    "            'eval_metric' : 'auc',\n",
    "            'eval_set': [(X_test, y_test)],\n",
    "            'callbacks': poss_cbs[cb],\n",
    "            'verbose': False,\n",
    "        }\n",
    "\n",
    "        xgb = XGBClassifier(\n",
    "            n_jobs=-1,\n",
    "            eval_metric='auc',\n",
    "            random_state=0,\n",
    "            n_estimators=100,\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            min_child_weight=min_child_weight,\n",
    "            subsample=subsample,\n",
    "            colsample_bynode=colsample_bynode,\n",
    "            num_parallel_tree=num_parallel_tree\n",
    "        )\n",
    "\n",
    "        xgb.fit(X_train, y_train, **fit_params)\n",
    "        p = xgb.predict_proba(X_test)[:, -1]\n",
    "        scores.append(metrics.roc_auc_score(y_test, p))\n",
    "    avg_score = np.mean(scores)\n",
    "    print(f\"Callback: {cb}, auc = {round(avg_score, 4)}\")\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_cb = cb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f340dc",
   "metadata": {
    "papermill": {
     "duration": 0.033159,
     "end_time": "2021-08-29T15:42:05.562640",
     "exception": false,
     "start_time": "2021-08-29T15:42:05.529481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finding the best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce4f5b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T15:42:05.639578Z",
     "iopub.status.busy": "2021-08-29T15:42:05.638521Z",
     "iopub.status.idle": "2021-08-29T15:42:11.867111Z",
     "shell.execute_reply": "2021-08-29T15:42:11.867621Z"
    },
    "papermill": {
     "duration": 6.27204,
     "end_time": "2021-08-29T15:42:11.867860",
     "exception": false,
     "start_time": "2021-08-29T15:42:05.595820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cross_val_probas = []\n",
    "ground_truths = []\n",
    "for fold in range(5):\n",
    "    train_data = train[train.fold != fold].copy()\n",
    "    test_data = train[train.fold == fold].copy()\n",
    "    X_train = train_data.drop(columns=['fold', 'y']).values\n",
    "    X_test = test_data.drop(columns=['fold', 'y']).values\n",
    "    y_train = train_data['y'].values\n",
    "    y_test = test_data['y'].values\n",
    "\n",
    "    fit_params = {\n",
    "        'early_stopping_rounds': 1000,\n",
    "        'eval_metric' : 'auc',\n",
    "        'eval_set': [(X_test, y_test)],\n",
    "        'callbacks': poss_cbs[best_cb],\n",
    "        'verbose': False,\n",
    "    }\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        n_jobs=-1,\n",
    "        eval_metric='auc',\n",
    "        random_state=0,\n",
    "        n_estimators=100,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        min_child_weight=min_child_weight,\n",
    "        subsample=subsample,\n",
    "        colsample_bynode=colsample_bynode,\n",
    "        num_parallel_tree=num_parallel_tree\n",
    "    )\n",
    "\n",
    "    xgb.fit(X_train, y_train, **fit_params)\n",
    "    p = xgb.predict_proba(X_test)[:, -1]\n",
    "    cross_val_probas += p.tolist()\n",
    "    ground_truths += y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc986f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T15:42:11.947925Z",
     "iopub.status.busy": "2021-08-29T15:42:11.947240Z",
     "iopub.status.idle": "2021-08-29T15:42:22.382376Z",
     "shell.execute_reply": "2021-08-29T15:42:22.382866Z"
    },
    "papermill": {
     "duration": 10.47933,
     "end_time": "2021-08-29T15:42:22.383058",
     "exception": false,
     "start_time": "2021-08-29T15:42:11.903728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX F1 SCORE: 0.6766169154228856, THRESH HOLD: 0.30340340340340344\n"
     ]
    }
   ],
   "source": [
    "best_th = 0\n",
    "f1_max = 0\n",
    "for th in np.linspace(0.1, 0.9, num=1000):\n",
    "    f1 = metrics.f1_score(np.asarray(ground_truths), (np.asarray(cross_val_probas) >= th).astype(int))\n",
    "    if f1_max < f1:\n",
    "        f1_max = f1\n",
    "        best_th = th\n",
    "print(f\"MAX F1 SCORE: {f1_max}, THRESH HOLD: {best_th}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034bc1c0",
   "metadata": {
    "papermill": {
     "duration": 0.033429,
     "end_time": "2021-08-29T15:42:22.451691",
     "exception": false,
     "start_time": "2021-08-29T15:42:22.418262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Final model and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34aaefe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T15:42:22.522411Z",
     "iopub.status.busy": "2021-08-29T15:42:22.521679Z",
     "iopub.status.idle": "2021-08-29T15:42:23.949840Z",
     "shell.execute_reply": "2021-08-29T15:42:23.950414Z"
    },
    "papermill": {
     "duration": 1.4646,
     "end_time": "2021-08-29T15:42:23.950608",
     "exception": false,
     "start_time": "2021-08-29T15:42:22.486008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train.copy()\n",
    "test_data = test.copy()\n",
    "X_train = train_data.drop(columns=['fold', 'y']).values\n",
    "X_test = test_data.values\n",
    "y_train = train_data['y'].values\n",
    "\n",
    "fit_params = {\n",
    "    'eval_metric' : 'auc',\n",
    "    'callbacks': poss_cbs[best_cb],\n",
    "    'verbose': False,\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_jobs=-1,\n",
    "    eval_metric='auc',\n",
    "    random_state=0,\n",
    "    n_estimators=100,\n",
    "    learning_rate=learning_rate,\n",
    "    max_depth=max_depth,\n",
    "    min_child_weight=min_child_weight,\n",
    "    subsample=subsample,\n",
    "    colsample_bynode=colsample_bynode,\n",
    "    num_parallel_tree=num_parallel_tree\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train, **fit_params)\n",
    "p = xgb.predict_proba(X_test)[:, -1]\n",
    "preds = p >= best_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bb2aafc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T15:42:24.027052Z",
     "iopub.status.busy": "2021-08-29T15:42:24.026073Z",
     "iopub.status.idle": "2021-08-29T15:42:24.084210Z",
     "shell.execute_reply": "2021-08-29T15:42:24.084650Z"
    },
    "papermill": {
     "duration": 0.098624,
     "end_time": "2021-08-29T15:42:24.084815",
     "exception": false,
     "start_time": "2021-08-29T15:42:23.986191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   0       True\n",
       "1   2       True\n",
       "2   4      False\n",
       "3   7       True\n",
       "4  15       True\n",
       "5  26      False\n",
       "6  44       True\n",
       "7  45      False\n",
       "8  57       True\n",
       "9  66      False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['predicted'] = preds\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1346.140258,
   "end_time": "2021-08-29T15:42:25.344212",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-29T15:19:59.203954",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1a14457b1c8840349487efa0f52a6fb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_661b6eeaf0bc42c9b1bde3f91ea1144c",
       "placeholder": "​",
       "style": "IPY_MODEL_daa5c85e60b648039f319940a8ab35d1",
       "value": "Cross validation progress: 100%"
      }
     },
     "2e67f0300da344b7ab6e2707f3170d6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "46a3acd66cb44d0cb56bd50e085fb9c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f627d904cc1419dbdd417422b7fa335",
       "placeholder": "​",
       "style": "IPY_MODEL_c87a4fd561bc477698598cfa7cfea2d6",
       "value": " 5/5 [00:14&lt;00:00,  2.92s/it]"
      }
     },
     "5f627d904cc1419dbdd417422b7fa335": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "661b6eeaf0bc42c9b1bde3f91ea1144c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91713af5a9394645aba64521c2a7fe78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1a14457b1c8840349487efa0f52a6fb1",
        "IPY_MODEL_b4be63cefb3445f0bba70af5342197f1",
        "IPY_MODEL_46a3acd66cb44d0cb56bd50e085fb9c4"
       ],
       "layout": "IPY_MODEL_a14db23c9e794286b716dab96f455d41"
      }
     },
     "9bf7224607d24110b0a79b9c4afc386d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a14db23c9e794286b716dab96f455d41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4be63cefb3445f0bba70af5342197f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2e67f0300da344b7ab6e2707f3170d6d",
       "max": 5,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9bf7224607d24110b0a79b9c4afc386d",
       "value": 5
      }
     },
     "c87a4fd561bc477698598cfa7cfea2d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "daa5c85e60b648039f319940a8ab35d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
